{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Opinion Mining & Sentiment Analysis: Lab Activities\n",
    "\n",
    "**Text Mining unit**\n",
    "\n",
    "_Prof. Gianluca Moro, Dott. Ing. Roberto Pasolini – DISI, University of Bologna_\n",
    "\n",
    "**Bologna Business School** - Alma Mater Studiorum Università di Bologna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Setup\n",
    "\n",
    "Import external libraries (thus verifying they are correctly installed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If using IPython/Jupyter, run the following to render plots inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Set some options in pandas for printing DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_colwidth = 100\n",
    "pd.options.display.precision = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a utility function to download data files if they are not already present in working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from urllib.request import urlretrieve\n",
    "def download(file, url):\n",
    "    if not os.path.exists(file):\n",
    "        urlretrieve(url, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Activity 1: Twitter Opinion Mining\n",
    "\n",
    "**Goal:** evaluate from Twitter how much customers are satisfied of airline companies\n",
    "\n",
    "1. Collect tweets citing airline companies\n",
    "2. Define lists of opinion keywords\n",
    "3. Evaluate sentiment of each tweet\n",
    "4. Summarize sentiment for each airline company\n",
    "5. Extract customer satisfaction for companies from the ACSI website\n",
    "6. Compare scores estimated from Twitter with those extracted from ACSI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "This is a list of the Twitter accounts of airline companies taken into consideration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "airlines = [\n",
    "    \"delta\",\n",
    "    \"americanair\",\n",
    "    \"jetblue\",\n",
    "    \"southwestair\",\n",
    "    \"united\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Collect tweets citing airline companies\n",
    "\n",
    "Recent tweets matching a given query can be searched using the Twitter Search API; many libraries exist for Python and other languages providing easy access to the API\n",
    "\n",
    "We see here how to obtain tweets using the `TwitterSearch` package, installable with `pip install TwitterSearch`; a Twitter account with an associated mobile number is needed in order to use the API\n",
    "\n",
    "If you can't or don't want to use your Twitter account and/or install the package, you can use a set of pre-collected tweets we provide"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Creating a Twitter application\n",
    "\n",
    "In order to use Twitter APIs you need API keys: follow these steps to obtain one\n",
    "\n",
    "1. Go to https://developer.twitter.com/en/apps and login with your Twitter account\n",
    "2. Click the \"Create New App\" button, fill the form with short descriptive values (you may use e.g. \"http://example.com\" as the URL) and confirm\n",
    "3. Click on the app you just created and open the \"Key and Access Tokens\" tab\n",
    "4. For better security, ensure to set the Access Level to Read-only\n",
    "5. Click on the \"Create my access token\" button below\n",
    "\n",
    "You will need strings labeled with _Consumer Key_, _Consumer Secret_, _Access Token_ and _Access Token Secret_ shown in the page to use the API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Authenticating\n",
    "\n",
    "Import the necessary classes and create a `TwitterSearch` object providing the API codes obtained above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from TwitterSearch import TwitterSearch, TwitterSearchOrder\n",
    "ts = TwitterSearch(\n",
    "    consumer_key=\"yWpAzNQudCFypHUACLVmeQ\",\n",
    "    consumer_secret=\"kCxyi29aVaZv7qQA1bM8Tt60rzUReD0Zaes2w6m1iU\",\n",
    "    access_token=\"1678583318-WAc1sc3oVuOqrU4DV3KZZAm024jyCic3kzMNtZl\",\n",
    "    access_token_secret=\"wjay7Z4uTMOXkEsRD4soIBMC7eCjG0Jk8giGDWOg\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Obtaining tweets\n",
    "\n",
    "Create a `TwitterSearchOrder` indicating the tweets to search: we start for example by searching tweets about Delta Air Lines, whose Twitter account is \"@delta\"; by default the search will return up to 100 tweets, the upper limit set by Twitter for each request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tso = TwitterSearchOrder()\n",
    "tso.set_keywords([\"@delta\"])\n",
    "tso.set_language(\"en\")\n",
    "tso.set_include_entities(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now issue the request to the Twitter API\n",
    "\n",
    "**Warning:** the Twitter API has usage rate limitations, `search_tweets` and other API methods will temporarily stop working if executed many times in few minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsresp = ts.search_tweets(tso)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We obtain an object with detailed information about the request and the response by Twitter, to obtain the list of tweets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_tweets = tsresp[\"content\"][\"statuses\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each tweet we have an object with many details: among the key ones we have its unique ID, the name of the author and its actual text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1133508786646392841"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta_tweets[0][\"id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DCHoosier'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta_tweets[0][\"user\"][\"name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'@Delta Many many thanks to Maria at B15 at DCA!! She is a superstar of customer service!!'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta_tweets[0][\"text\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Define a function to repeat the operations given above on any search string and return a list of the contents of each tweet (without metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recent_tweets(query):\n",
    "    print(\"getting tweets for '{}' ... \".format(query), end=\"\")\n",
    "    tso = TwitterSearchOrder()\n",
    "    tso.set_keywords([query])\n",
    "    tso.set_language(\"en\")\n",
    "    tso.set_include_entities(False)\n",
    "    tsresp = ts.search_tweets(tso)\n",
    "    texts = [status[\"text\"] for status in tsresp[\"content\"][\"statuses\"]]\n",
    "    print(\"{} retrieved\".format(len(texts)))\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Use then this function to create a dictionary mapping airline names to list of relevant tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting tweets for '@delta' ... 100 retrieved\n",
      "getting tweets for '@americanair' ... 100 retrieved\n",
      "getting tweets for '@jetblue' ... 100 retrieved\n",
      "getting tweets for '@southwestair' ... 100 retrieved\n",
      "getting tweets for '@united' ... 99 retrieved\n"
     ]
    }
   ],
   "source": [
    "current_tweets = {\n",
    "    airline: get_recent_tweets(\"@\" + airline)\n",
    "    for airline in airlines\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Using pre-collected tweets\n",
    "\n",
    "For convenience, we provide a set of precollected tweets about the airline companies as an alternative to latest tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "download(\"tweets.zip\", \"https://www.dropbox.com/s/umqtqi9bwvlrr6z/tweets.zip?dl=1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ZIP archive contains a `company_name.txt` file for each airline company, each with a list of tweets (one per line): we load them into a dict mapping the name of each company to the list of relevant tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "archive_tweets = {}\n",
    "with ZipFile(\"tweets.zip\") as zipf:\n",
    "    for airline in airlines:\n",
    "        with zipf.open(airline + \".txt\") as f:\n",
    "            archive_tweets[airline] = list(line.decode().strip() for line in f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "You can read for example some tweets about Delta airlines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\"@LAKings: Are you the #LAKings biggest fan? Prove it and win a trip on @Delta to see the Kings vs Rangers in NY - http://t.co/JXBc5kDXnZ\"RT',\n",
       " '@AneetharPweety am @delta state buh on ma way to benin city now',\n",
       " 'RT @iamdiddy: If you’re flying out of JFK on @Delta you NEED to check out the new @CIROC VIP lounge at @Delta terminal at JFK. http://t.co/…']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "archive_tweets[\"delta\"][:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following we will work on these `archive_tweets`, replace that in the line below with `current_tweets` if you want to use downloaded tweets instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = archive_tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "To better deal with them later, we represents tweets into a pandas DataFrame with two columns\n",
    "- a `text` column with the text of the tweet\n",
    "- an `airline` column with the airline each tweet refers to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pd.DataFrame(\n",
    "    {\"airline\": airline, \"text\": text}\n",
    "    for airline, tweetlist in tweets.items()\n",
    "    for text in tweetlist\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>southwestair</td>\n",
       "      <td>Darn you southwest and your cheap online deals! So tempting.. #travel @SouthwestAir</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>southwestair</td>\n",
       "      <td>@LedddyLuv @SouthwestAir so jealous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>southwestair</td>\n",
       "      <td>Ah, sales on @SouthwestAir - well, it's like the early Christmas gift you say you deserve to buy...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        airline  \\\n",
       "0  southwestair   \n",
       "1  southwestair   \n",
       "2  southwestair   \n",
       "\n",
       "                                                                                                  text  \n",
       "0                  Darn you southwest and your cheap online deals! So tempting.. #travel @SouthwestAir  \n",
       "1                                                                  @LedddyLuv @SouthwestAir so jealous  \n",
       "2  Ah, sales on @SouthwestAir - well, it's like the early Christmas gift you say you deserve to buy...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Estimating sentiment using lists of opinion words\n",
    "\n",
    "Several methods and algorithms have been proposed in literature to estimate the sentiment of a document (or sentence), usually quite complex.\n",
    "\n",
    "To get started, we will use a trivial lexicon-based method which assigns a score by counting known positive and negative words in each tweet.\n",
    "\n",
    "Hu and Liu made available for download a list of about 6,800 words labeled as either positive or negative.\n",
    "\n",
    "- **Positive:** love, best, cool, great, good, amazing, ...\n",
    "- **Negative:** hate, worst, sucks, awful, nightmare, ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We write\n",
    "- a function used to process word lists, ignoring lines either empty or starting with \";\" (comments)\n",
    "- another function using the first one to get a set of words contained in a named file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scan_hu_liu(f):\n",
    "    for line in f:\n",
    "        line = line.decode(errors=\"ignore\").strip()\n",
    "        if line and not line.startswith(\";\"):\n",
    "            yield line\n",
    "\n",
    "def load_hu_liu(filename):\n",
    "    with open(filename, \"rb\") as f:\n",
    "        return set(scan_hu_liu(f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We then download the two sets (one for positive words and one for negative ones) and use the latter function to load them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "download(\"positive-words.txt\", \"https://www.dropbox.com/s/pmju477pv8ayzho/positive-words.txt?dl=1\")\n",
    "download(\"negative-words.txt\", \"https://www.dropbox.com/s/yy4l1ezlrsar8cf/negative-words.txt?dl=1\")\n",
    "hu_liu_pos = load_hu_liu(\"positive-words.txt\")\n",
    "hu_liu_neg = load_hu_liu(\"negative-words.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The words in the list are general, but we can add some domain-specific word (\"`|`\" is the \"set union\" operator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "airline_pos_words = hu_liu_pos | {\"upgrade\"}\n",
    "airline_neg_words = hu_liu_neg | {\"wtf\", \"wait\", \"waiting\", \"epicfail\", \"mechanical\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "_Performance note:_ we use sets here (denoted with braces: `{...}`) rather than lists (with square brackets: `[...]`) to make lookup faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63.4 ns ± 0.932 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 1000000\n",
    "\"e\" in [\"a\", \"b\", \"c\", \"d\", \"e\"]   # list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21.6 ns ± 0.497 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 1000000\n",
    "\"e\" in {\"a\", \"b\", \"c\", \"d\", \"e\"}   # set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Text tokenization\n",
    "\n",
    "We have to decompose tweets into the single words they contain in order to search for the opinion words within it\n",
    "\n",
    "A _tokenization_ algorithm splits a text string into a sequence of _tokens_ each representing a single word (or other entities such as numbers and punctuation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "A simple tokenization algorithm can consist in removing all characters different from letters and spaces from text, than splitting text in words using spaces as boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def my_tokenizer(text):\n",
    "    return re.sub(\"[^A-Za-z ]\", \"\", text).split(\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example usage is..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This', 'isnt', 'a', 'test', 'or', 'is', 'it']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_tokenizer(\"This isn't a test, or is it?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "NLTK provides a finer tokenization algorithm, based on a knowledge model of the English language: in order to make it work, we have first to download the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/rrobby/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then use the `word_tokenize` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This', 'is', \"n't\", 'a', 'test', ',', 'or', 'is', 'it', '?']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.word_tokenize(\"This isn't a test, or is it?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other than keeping punctuation marks as separate tokens, NLTK was able to correctly split \"isn't\" into its two component words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Sentiment scoring\n",
    "\n",
    "We define a function to compute the \"sentiment score\" of some text, computed as the difference between counts of positive and negative opinion words contained in it. Notice we have to convert all words in lowercase to be sure to find them in the lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_score(text, pos_words, neg_words):\n",
    "    words = nltk.word_tokenize(text)\n",
    "    # count 1 for each word present in the positive words list\n",
    "    pos_matches = sum(1 for word in words if word.lower() in pos_words)\n",
    "    # same count with the negative words list\n",
    "    neg_matches = sum(1 for word in words if word.lower() in neg_words)\n",
    "    # return the difference between the two counts\n",
    "    return pos_matches - neg_matches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "This functions accept the lists of positive and negative words as input, we can wrap it in a version specific for the \"airline\" opinion words lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def airline_sentiment_score(text):\n",
    "    return sentiment_score(text, airline_pos_words, airline_neg_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example: a sentence with one positive word..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airline_sentiment_score(\"This is an awesome test!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's consider a small set of sample sentences to evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = [\n",
    "    \"You're awesome and I love you\",\n",
    "    \"I hate and hate and hate. So angry. Die!\",\n",
    "    \"Impressed and amazed: you are peerless in your achievement of unparalleled mediocrity.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use `map` to apply the scoring function to each of the samples and get the sequence of corresponding scores wrapped in a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_scores = list(map(airline_sentiment_score, sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, -5, 4]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Using a pandas DataFrame, we can get a table of sample sentences matched with scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>You're awesome and I love you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-5</td>\n",
       "      <td>I hate and hate and hate. So angry. Die!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>Impressed and amazed: you are peerless in your achievement of unparalleled mediocrity.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   score  \\\n",
       "0      2   \n",
       "1     -5   \n",
       "2      4   \n",
       "\n",
       "                                                                                     text  \n",
       "0                                                           You're awesome and I love you  \n",
       "1                                                I hate and hate and hate. So angry. Die!  \n",
       "2  Impressed and amazed: you are peerless in your achievement of unparalleled mediocrity.  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\"score\": sample_scores, \"text\": sample})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the scoring function correctly evaluates straightforward sentences, although it fails to detect more elaborate text (e.g. using sarcasm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's apply the scoring functions to all tweets for one of the companies, e.g. Delta. We wrap scores in a pandas Series so we can use its functionalities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_scores = pd.Series(map(airline_sentiment_score, tweets[\"text\"][tweets[\"airline\"] == \"delta\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get for example the mean score of tweets..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23406113537117904"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta_scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "...and even plot an histogram of the distribution of scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fd6af349518>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "delta_scores.plot.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's now work with the whole collection of tweets related to all airlines\n",
    "\n",
    "We compute sentiment scores for each tweet by applying the `airline_sentiment_score` function to the `text` columns; scores are saved in a `score` column added to a copy of the `tweets` DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_with_scores = tweets.copy()\n",
    "tweets_with_scores[\"score\"] = tweets_with_scores[\"text\"].apply(airline_sentiment_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see some random rows from it..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline</th>\n",
       "      <th>text</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4246</th>\n",
       "      <td>united</td>\n",
       "      <td>@united Thanks they book me ok. No way to get there today, but hotel in Sjo said will charge the...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3117</th>\n",
       "      <td>americanair</td>\n",
       "      <td>ope so too; #Pasta dishes on AA int'l flights are the ones I have tasted &amp;amp; like.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4239</th>\n",
       "      <td>united</td>\n",
       "      <td>Yup. RT @nyc2theworld: @joelfreak @WanderngAramean @united EWR airport rail station...i recogniz...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2460</th>\n",
       "      <td>americanair</td>\n",
       "      <td>Seeing a lot more @AmericanAir planes with the new trade dress.  Not mine today, tho. Maybe tomo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3180</th>\n",
       "      <td>united</td>\n",
       "      <td>hey @united can you email my teacher, because I have class tomorrow and your delays are killing ...</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          airline  \\\n",
       "4246       united   \n",
       "3117  americanair   \n",
       "4239       united   \n",
       "2460  americanair   \n",
       "3180       united   \n",
       "\n",
       "                                                                                                     text  \\\n",
       "4246  @united Thanks they book me ok. No way to get there today, but hotel in Sjo said will charge the...   \n",
       "3117                 ope so too; #Pasta dishes on AA int'l flights are the ones I have tasted &amp; like.   \n",
       "4239  Yup. RT @nyc2theworld: @joelfreak @WanderngAramean @united EWR airport rail station...i recogniz...   \n",
       "2460  Seeing a lot more @AmericanAir planes with the new trade dress.  Not mine today, tho. Maybe tomo...   \n",
       "3180  hey @united can you email my teacher, because I have class tomorrow and your delays are killing ...   \n",
       "\n",
       "      score  \n",
       "4246      0  \n",
       "3117      1  \n",
       "4239     -1  \n",
       "2460      0  \n",
       "3180     -2  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_with_scores.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Summarizing sentiment for each company\n",
    "\n",
    "Let’s focus our analysis only on very negative (score <= 2) and very positive (score >= 2) tweets, adding columns which identify them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_with_scores[\"very_pos\"] = tweets_with_scores[\"score\"] >= 2\n",
    "tweets_with_scores[\"very_neg\"] = tweets_with_scores[\"score\"] <= -2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We group the frame by companies, keeping just the columns indicating very positive or negative tweets and counting the number of them for each group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_score = tweets_with_scores.groupby(\"airline\")[\"very_pos\", \"very_neg\"].sum().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's view the obtained grouped table..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>very_pos</th>\n",
       "      <th>very_neg</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>airline</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>americanair</th>\n",
       "      <td>118.0</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>delta</th>\n",
       "      <td>116.0</td>\n",
       "      <td>55.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jetblue</th>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>southwestair</th>\n",
       "      <td>122.0</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>united</th>\n",
       "      <td>116.0</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              very_pos  very_neg\n",
       "airline                         \n",
       "americanair      118.0      31.0\n",
       "delta            116.0      55.0\n",
       "jetblue           10.0       2.0\n",
       "southwestair     122.0      34.0\n",
       "united           116.0      99.0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`airline` is now the _index_ of the frame: values of the index identify each row (much like a primary key in a database)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "For every company, we compute the sum of very positive and very negative tweets..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_score[\"all_count\"] = twitter_score.very_pos + twitter_score.very_neg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...then we compute a \"global sentiment score\" as the percentage between the count of positive tweets and the total count of tweets above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_score[\"score\"] = 100 * twitter_score.very_pos / twitter_score.all_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's now list the companies ranked by their score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>very_pos</th>\n",
       "      <th>very_neg</th>\n",
       "      <th>all_count</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>airline</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>jetblue</th>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>83.333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>americanair</th>\n",
       "      <td>118.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>79.195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>southwestair</th>\n",
       "      <td>122.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>78.205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>delta</th>\n",
       "      <td>116.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>67.836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>united</th>\n",
       "      <td>116.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>215.0</td>\n",
       "      <td>53.953</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              very_pos  very_neg  all_count   score\n",
       "airline                                            \n",
       "jetblue           10.0       2.0       12.0  83.333\n",
       "americanair      118.0      31.0      149.0  79.195\n",
       "southwestair     122.0      34.0      156.0  78.205\n",
       "delta            116.0      55.0      171.0  67.836\n",
       "united           116.0      99.0      215.0  53.953"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_score.sort_values(\"score\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "To simplify subsequent tests, we create a function which, given a series of scores for tweets, executes the steps above to extract summary scores for each airline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_summary_scores(tweet_scores):\n",
    "    very_pos_tweets = tweet_scores >= 2\n",
    "    very_neg_tweets = tweet_scores <= -2\n",
    "    very_pos = very_pos_tweets.groupby(tweets[\"airline\"]).sum()\n",
    "    very_neg = very_neg_tweets.groupby(tweets[\"airline\"]).sum()\n",
    "    total = very_pos + very_neg\n",
    "    return 100 * (very_pos / total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Comparing results with known customer satisfaction\n",
    "\n",
    "We can extract known information about the general satisfaction of airline companies from the ACSI (_American Customer Satisfaction Index_) website\n",
    "\n",
    "A table of the satisfaction index by year about airline companies is available at http://www.theacsi.org/index.php?option=com_content&view=article&id=147&catid=&Itemid=212&i=Airlines\n",
    "\n",
    "We can import such data and use it to validate the satisfaction score extracted from Twitter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "pandas provides the `read_html` function to get DataFrames by scraping tables from a Web page (the `lxml` and `BeautifulSoup4` packages must be installed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "acsi_table = pd.read_html(\n",
    "    \"http://www.theacsi.org/index.php?option=com_content&view=article&id=147&catid=&Itemid=212&i=Airlines\",\n",
    "    header=0, index_col=0)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>PreviousYear%Change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Alaska</th>\n",
       "      <td>77.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Southwest</th>\n",
       "      <td>80.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>-1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JetBlue</th>\n",
       "      <td>80.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Delta</th>\n",
       "      <td>71.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Airlines</th>\n",
       "      <td>72.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             16    17    18    19  PreviousYear%Change\n",
       "Alaska     77.0  78.0  79.0  80.0                  1.3\n",
       "Southwest  80.0  80.0  80.0  79.0                 -1.3\n",
       "JetBlue    80.0  82.0  79.0  79.0                  0.0\n",
       "Delta      71.0  76.0  74.0  75.0                  1.4\n",
       "Airlines   72.0  75.0  73.0  74.0                  1.4"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acsi_table.iloc[:5,-5:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We select the column \"13\" for the year when tweets were extracted (use \"19\" in case you are analyzing current tweets) and the rows related to analyzed companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "airline_names = [\"Southwest\", \"JetBlue\", \"American\", \"Delta\", \"United\"]\n",
    "acsi_score = acsi_table.loc[airline_names, \"13\"].astype(float).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "American     65.0\n",
       "Delta        68.0\n",
       "JetBlue      83.0\n",
       "Southwest    81.0\n",
       "United       62.0\n",
       "Name: 13, dtype: float64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acsi_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In case you miss the required libraries, here are two alternative instructions to create the ACSI scores series without using the `read_html` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2019 (current_tweets)\n",
    "acsi_score = pd.Series(\n",
    "          [      79.0 ,     79.0 ,      73.0 ,   75.0 ,    70.0 ],\n",
    "    index=[\"Southwest\", \"JetBlue\", \"American\", \"Delta\", \"United\"]\n",
    ").sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2013 (archive_tweets)\n",
    "acsi_score = pd.Series(\n",
    "          [      81.0 ,     83.0 ,      65.0 ,   68.0 ,    62.0 ],\n",
    "    index=[\"Southwest\", \"JetBlue\", \"American\", \"Delta\", \"United\"]\n",
    ").sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We extracted a single column of the table along with the index containing company names: we change names in order to match the index from `twitter_scores`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "acsi_score.index = (acsi_score.index\n",
    "                    .str.lower()\n",
    "                    .str.replace(\"american\", \"americanair\")\n",
    "                    .str.replace(\"southwest\", \"southwestair\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "americanair     65.0\n",
       "delta           68.0\n",
       "jetblue         83.0\n",
       "southwestair    81.0\n",
       "united          62.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acsi_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We have now the `acsi_score` series and the `score` column of the `twitter_score` frame indexed with the same labels, but in different order: we can merge them into a new frame to align the series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acsi</th>\n",
       "      <th>twitter</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>airline</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>americanair</th>\n",
       "      <td>65.0</td>\n",
       "      <td>79.195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>delta</th>\n",
       "      <td>68.0</td>\n",
       "      <td>67.836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jetblue</th>\n",
       "      <td>83.0</td>\n",
       "      <td>83.333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>southwestair</th>\n",
       "      <td>81.0</td>\n",
       "      <td>78.205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>united</th>\n",
       "      <td>62.0</td>\n",
       "      <td>53.953</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              acsi  twitter\n",
       "airline                    \n",
       "americanair   65.0   79.195\n",
       "delta         68.0   67.836\n",
       "jetblue       83.0   83.333\n",
       "southwestair  81.0   78.205\n",
       "united        62.0   53.953"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\"twitter\": twitter_score[\"score\"], \"acsi\": acsi_score})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We can now evaluate the degree of agreement between the two scores: we may do it graphically using a _scatter plot_..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(twitter_score[\"score\"], acsi_score, s=50) # plot points\n",
    "plt.plot([50, 100], [50, 100], \"r--\")          # plot a x=y segment\n",
    "plt.xlabel(\"Twitter score\")\n",
    "plt.ylabel(\"ACSI score\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each point indicates the scores of a company, the dashed line indicates where scores match: the most the points are close to the line, the most the scores agree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "To properly verify the agreement of the two scores, we measure the _Pearson's correlation coefficient_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.722923515861678, 0.1676117280084561)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import pearsonr\n",
    "pearsonr(twitter_score[\"score\"], acsi_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first value is the Pearson's coefficient, while the second value is the associated p-value, i.e. the probability that the correlation between the two series was obtained by chance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exercise 1: interpreting negations\n",
    "\n",
    "In the `sentiment_score` function, when we look for positive or negative words, we do not consider whether they are negated\n",
    "\n",
    "**A)** The `sentiment_score_neg` function below implements the same logic of `sentiment_score` so that it can be more easily changed: modify it in order to count any positive word immediately preceded by \"not\" (case-insensitive) as negative and vice versa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_score_neg(text, pos_words, neg_words):\n",
    "    words = nltk.word_tokenize(text)\n",
    "    score = 0\n",
    "    for i in range(len(words)):\n",
    "        word_score = 0\n",
    "        if words[i] in pos_words:\n",
    "            word_score = 1\n",
    "        elif words[i] in neg_words:\n",
    "            word_score = -1\n",
    "        score += word_score\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**B)** Create a series `tweet_scores_neg` with scores of tweets in `tweets[\"text\"]`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**C)** Compute the mean absolute difference between this previous score and the new score of each tweet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**D)** Use the `get_summary_scores` defined above to get a series `twitter_score_neg` with summary scores for each airline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**E)** Verify the correlation between the new Twitter score and the ACSI score using a scatter plot and Pearson's coefficient as above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Activity 2: Sentiment Analysis at sentence and feature level\n",
    "\n",
    "We reuse techniques seen above to perform sentiment analysis at sentence and feature level on reviews of hotels\n",
    "\n",
    "TripAdvisor used to provide a summary of hotel ratings against 6 different features: **Location, Sleep Quality, Rooms, Service, Value, Cleanliness**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Activity plan\n",
    "\n",
    "1. Define lists of opinion and feature words\n",
    "  - for opinion words, we reuse the lists of Hu and Liu from above\n",
    "2. Break reviews into sentences\n",
    "3. Detect sentences dealing with a specific feature and score its sentiment\n",
    "4. Summarize evaluation of each hotel and each feature\n",
    "5. Compare features of each hotel\n",
    "6. Compare results with scores on TripAdvisor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Loading reviews\n",
    "\n",
    "We provide a ZIP file with reviews of 6 different Hotels in Chicago, in a format similar to that of airline tweets used above (one file per hotel, one review per line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "download(\"hotel-reviews.zip\", \"https://www.dropbox.com/s/l46r5601h9vjfz9/hotel-reviews.zip?dl=1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "import re\n",
    "all_reviews = {}\n",
    "filename_pattern = re.compile(\"usa_illinois_chicago_([a-z_]+).txt\")\n",
    "with ZipFile(\"hotel-reviews.zip\") as zip:\n",
    "    for filename in zip.namelist():\n",
    "        hotel = filename_pattern.match(filename).group(1)\n",
    "        with zip.open(filename) as f:\n",
    "            all_reviews[hotel] = list(line.decode(errors=\"ignore\").strip() for line in f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "As an example, we will use reviews for the Intercontinental hotel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_interc = all_reviews[\"intercontinental_chicago\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A great spot! We have always been pleased with our stays at Intercontinental hotels. Chicago was especially pleasant with a helpful staff.'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_interc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Lists of feature words\n",
    "\n",
    "To detect sentences dealing with a specific feature, we search for feature-related keywords\n",
    "\n",
    "Using only the names of the 6 features as keywords, would produce few results: lists of _feature words_ which are synonyms or anyhow else related to each feature is created (manually in this case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "feature_words = {\n",
    "    'location': {'location', 'airport', 'center', 'island', 'lake', 'ocean',\n",
    "                 'sea', 'around', 'university', 'romantic', 'coast', 'beach',\n",
    "                 'disco', 'nightlife'},\n",
    "    'sleepquality': {'silence','sleep','night','noise','nightlife'},\n",
    "    'rooms': {'room', 'rooms', 'space', 'bed', 'bath', 'bathroom', 'toilet',\n",
    "              'degrade', 'disorder','shower','jacuzzi','frigo'},\n",
    "    'service': {'service','pet','friendly','swimming', 'pool', 'pools', 'spa',\n",
    "                'waiters', 'severs', 'waiter', 'manservant', 'cordial',\n",
    "                'hearty', 'restorative', 'disagreeable', 'unpleasant',\n",
    "                'restaurant', 'food', 'breakfast', 'lunch', 'dinner', 'bar'},\n",
    "    'value': {'cheap','affordable','afford','woth', 'price', 'value', 'cost',\n",
    "              'expensive', 'economical', 'depreciate', 'discount', 'luxury',\n",
    "              'hall', 'meal'},\n",
    "    'cleanliness': {'clean', 'cleanliness', 'place', 'neatness', 'sweeping',\n",
    "                    'dirty', 'soiled', 'grubby', 'foul', 'mucky'}\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Breaking reviews into sentences\n",
    "\n",
    "We break reviews into single sentences, assuming that each sentence deals with (at most) one of the features\n",
    "\n",
    "Breaking text into sentences (_sentence tokenization_) is not straightforward: sentences usually end with a period (\".\"), but may also end with other punctuation (\"!\", \"?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "This is an example of function for sentence tokenization, which splits text on \".\", \"?\" and \"!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_sent_tokenizer(text):\n",
    "    return re.split(\"[\\\\.\\\\?!]\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A great spot',\n",
       " ' We have always been pleased with our stays at Intercontinental hotels',\n",
       " ' Chicago was especially pleasant with a helpful staff',\n",
       " '']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_sent_tokenizer(reviews_interc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However this function fails when these characters are used in the middle of a sentence, e.g. in an ellipsis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This works', '', '', ' or not', ' Maybe not', '']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_sent_tokenizer(\"This works... or not? Maybe not.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Similarly to the word tokenizer used above, NLTK provides a sentence tokenizer based on knowledge of English language to detect such exceptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This works... or not?', 'Maybe not.']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.sent_tokenize(\"This works... or not? Maybe not.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this tokenization function, we turn the list of reviews into a list of single sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_interc = [sent for review in reviews_interc for sent in nltk.sent_tokenize(review)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Detecting features and opinions in sentences\n",
    "\n",
    "We define a function which counts, for each feature, the number of sentences in a given list expressing a positive or negative judgement about it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_pos_neg_counts(sentences, feature_words, pos_words, neg_words):\n",
    "    # initialize to 0 counts of positive and negative sentences per feature\n",
    "    pos_counts = {feat: 0 for feat in feature_words.keys()}\n",
    "    neg_counts = {feat: 0 for feat in feature_words.keys()}\n",
    "    for sent in sentences:\n",
    "        # evaluate sentiment of sentence\n",
    "        word_list = nltk.word_tokenize(sent)\n",
    "        pos_word_count = sum(1 for word in word_list if word in pos_words)\n",
    "        neg_word_count = sum(1 for word in word_list if word in neg_words)\n",
    "        sent_score = pos_word_count - neg_word_count\n",
    "        # detect features in sentence\n",
    "        word_set = set(word_list)\n",
    "        for feat, keywords in feature_words.items():\n",
    "            if word_set & keywords:   # if intersection is not empty\n",
    "                if sent_score > 0:\n",
    "                    pos_counts[feat] += 1\n",
    "                elif sent_score < 0:\n",
    "                    neg_counts[feat] += 1\n",
    "    return pd.DataFrame({\"pos_count\": pos_counts, \"neg_count\": neg_counts})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "For each list of sentences, the function returns a DataFrame with counts of positive and negative sentences for each feature\n",
    "\n",
    "Let's apply it for example to reviews of Intercontinental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_interc = feature_pos_neg_counts(sentences_interc, feature_words, hu_liu_pos, hu_liu_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neg_count</th>\n",
       "      <th>pos_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cleanliness</th>\n",
       "      <td>11</td>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>location</th>\n",
       "      <td>18</td>\n",
       "      <td>231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rooms</th>\n",
       "      <td>92</td>\n",
       "      <td>423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>service</th>\n",
       "      <td>55</td>\n",
       "      <td>370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sleepquality</th>\n",
       "      <td>28</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>value</th>\n",
       "      <td>34</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              neg_count  pos_count\n",
       "cleanliness          11        131\n",
       "location             18        231\n",
       "rooms                92        423\n",
       "service              55        370\n",
       "sleepquality         28         50\n",
       "value                34         70"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_interc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Summarizing evaluation of hotel features\n",
    "\n",
    "Similarly to above, we compute for each feature a sentiment score in a 0-50 scale from the ratio of positive sentences about a feature w.r.t. their total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_interc[\"tot_count\"] = scores_interc.pos_count + scores_interc.neg_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_interc[\"score\"] = round(50 * scores_interc.pos_count / scores_interc.tot_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neg_count</th>\n",
       "      <th>pos_count</th>\n",
       "      <th>tot_count</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cleanliness</th>\n",
       "      <td>11</td>\n",
       "      <td>131</td>\n",
       "      <td>142</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>location</th>\n",
       "      <td>18</td>\n",
       "      <td>231</td>\n",
       "      <td>249</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rooms</th>\n",
       "      <td>92</td>\n",
       "      <td>423</td>\n",
       "      <td>515</td>\n",
       "      <td>41.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>service</th>\n",
       "      <td>55</td>\n",
       "      <td>370</td>\n",
       "      <td>425</td>\n",
       "      <td>44.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sleepquality</th>\n",
       "      <td>28</td>\n",
       "      <td>50</td>\n",
       "      <td>78</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>value</th>\n",
       "      <td>34</td>\n",
       "      <td>70</td>\n",
       "      <td>104</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              neg_count  pos_count  tot_count  score\n",
       "cleanliness          11        131        142   46.0\n",
       "location             18        231        249   46.0\n",
       "rooms                92        423        515   41.0\n",
       "service              55        370        425   44.0\n",
       "sleepquality         28         50         78   32.0\n",
       "value                34         70        104   34.0"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_interc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In order to easily repeat this process for every hotel, we wrap it in a function which takes as input the list of reviews and returns the Series with the final scores per feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_scores(reviews, feature_words, pos_words, neg_words):\n",
    "    sentences = [sent for review in reviews for sent in nltk.sent_tokenize(review)]\n",
    "    counts = feature_pos_neg_counts(sentences, feature_words, pos_words, neg_words)\n",
    "    total = counts.pos_count + counts.neg_count\n",
    "    return round(50 * counts.pos_count / total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cleanliness     46.0\n",
       "location        46.0\n",
       "rooms           41.0\n",
       "service         44.0\n",
       "sleepquality    32.0\n",
       "value           34.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_scores(reviews_interc, feature_words, hu_liu_pos, hu_liu_neg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's create a DataFrame with feature scores for all analyzed hotels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = pd.DataFrame({hotel: feature_scores(reviews, feature_words, hu_liu_pos, hu_liu_neg) for hotel, reviews in all_reviews.items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cleanliness</th>\n",
       "      <th>location</th>\n",
       "      <th>rooms</th>\n",
       "      <th>service</th>\n",
       "      <th>sleepquality</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>affinia_chicago</th>\n",
       "      <td>46.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hyatt_regency_chicago</th>\n",
       "      <td>42.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>intercontinental_chicago</th>\n",
       "      <td>46.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>james_chicago</th>\n",
       "      <td>46.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>swissotel_chicago</th>\n",
       "      <td>46.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the_palmer_house_hilton</th>\n",
       "      <td>44.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          cleanliness  location  rooms  service  sleepquality  \\\n",
       "affinia_chicago                  46.0      45.0   42.0     45.0          25.0   \n",
       "hyatt_regency_chicago            42.0      45.0   37.0     39.0          27.0   \n",
       "intercontinental_chicago         46.0      46.0   41.0     44.0          32.0   \n",
       "james_chicago                    46.0      47.0   41.0     44.0          30.0   \n",
       "swissotel_chicago                46.0      44.0   40.0     43.0          32.0   \n",
       "the_palmer_house_hilton          44.0      45.0   37.0     40.0          26.0   \n",
       "\n",
       "                          value  \n",
       "affinia_chicago            39.0  \n",
       "hyatt_regency_chicago      30.0  \n",
       "intercontinental_chicago   34.0  \n",
       "james_chicago              35.0  \n",
       "swissotel_chicago          34.0  \n",
       "the_palmer_house_hilton    35.0  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.T   # transpose the table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We can create a bar plot to compare the hotels by each feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fd6ac771e48>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEvCAYAAABVKjpnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3Xd8VGXWwPHfSQgEll4EFKVYaMkkJITQe1MRYQWRZRVQQTqWRRFcRGAVFQuwvFJe+otKt4CuGgEpgiTBBCmR4galCggxoQgJz/vHTMaUSTJJJpnkcr6fTz7k3pl777mZcPLc5z73PGKMQSmlVPHn4+0AlFJKeYYmdKWUsghN6EopZRGa0JVSyiI0oSullEVoQldKKYvQhK6UUhahCV0ppSxCE7pSSllEicI8WNWqVU2dOnUK85BKKVXsRUdHnzPGVMvpfYWa0OvUqUNUVFRhHlIppYo9ETnmzvu0y0UppSxCE7pSSlmEJnSllLKIQu1DV6qou379OsePH+fq1aveDkXdhPz9/alVqxZ+fn552l4TulJpHD9+nHLlylGnTh1ExNvhqJuIMYbz589z/Phx6tatm6d9aJeLUmlcvXqVKlWqaDJXhU5EqFKlSr6uDjWhK5WBJnPlLfn93dOErpRSFqF96Eplo874jR7dX/z0+z26P6XS0hZ6MXawQcN0X8q6Vq9eTcOGDenQoQMA/fv3x2az8c477zBp0iQiIiKy3f6TTz5h+vTpHounbNmyLtfPnTuXZcuWeew4Kne0ha5UMbBw4UIWLFhA69atOX36NJGRkRw5csTt7Xv27EnPnj0LMEK7YcOGFfgxVNa0ha5UEdOrVy9CQ0Np3Lgx8+fPZ8qUKWzfvp0nnniCcePG0bVrV06cOEFwcDDbtm1j0KBBrFmzBrDXS3r55ZcJCQkhMDCQuLg4AJYsWcKoUaMA+PTTTwkPD6dJkyZ07tyZM2fOZBlLUlISgwcPJjAwEJvNxtq1a52vTZw4kaCgIJo3b+7cx+TJk5kxYwYAR44coXPnzgQFBRESEsLRo0dJSkqiU6dOzvg+/vhj5/6mTp1K/fr1ad26Nf3793fuJyYmhubNm2Oz2ejduzcXLlzw4E/bWjShK1XELFq0iOjoaKKiopg1axYjR46kadOmrFixgjfffJNPPvmEO++8k5iYGNq0aZNp+6pVq7Jnzx6GDx/uTIpptW7dml27dvH999/zyCOP8MYbb2QZy9SpU6lQoQI//PADe/fupWPHjgBcunSJ5s2bExsbS9u2bVmwYEGmbQcMGMDIkSOJjY3l22+/pWbNmvj7+7N+/Xr27NnD5s2bee655zDGEBkZydq1a4mNjeXzzz9PV8Tvscce4/XXX2fv3r0EBgbyyiuv5OXHelMoFl0uGW9MubqxFLg0MNO6Va8lp1ve1H5OpveMnNsxn9EVDpfn54U4VMGbNWsW69evB+CXX37h8OHDudr+r3/9KwChoaGsW7cu0+vHjx+nX79+nDp1imvXrmX7EEtERAQffvihc7lSpUoAlCxZkh49ejiP89VXX6XbLjExkRMnTtC7d2/A/gQk2J/EnTBhAlu3bsXHx4cTJ05w5swZduzYwYMPPoi/vz/+/v488MADACQkJHDx4kXatWsHwMCBA+nbt2+ufh43E22hK1WEbNmyhYiICHbu3ElsbCxNmjTJ9YMmpUqVAsDX15fk5ORMr48ePZpRo0bxww8/MG/evDw9yOLn5+ccM53VcVxZsWIFZ8+eJTo6mpiYGKpXr65lFjyoWLTQlfKWwh5mmJCQQKVKlShTpgxxcXHs2rWrQI5x2223AbB06dJs39ulSxfmzJnDu+++C8CFCxecrfTslCtXjlq1avHRRx/Rq1cv/vjjD1JSUkhISOCWW27Bz8+PzZs3c+yYvcx3q1ateOqpp3jxxRdJTk5mw4YNDB06lAoVKlCpUiW2bdtGmzZtWL58ubO1rjLTFrpSRUj37t1JTk6mYcOGjB8/nubNm3v8GJMnT6Zv376EhoZStWrVbN/70ksvceHCBQICAggKCmLz5s1uH2f58uXMmjULm81Gy5YtOX36NAMGDCAqKorAwECWLVtGgwYNAAgLC6Nnz57YbDbuvfdeAgMDqVChAmD/ozNu3DhsNhsxMTFMmjQp7ydvcWKMKbSDNW3a1ORlxiLtQ3fv/BrGHSyscCzr4MGDNGyoY/q9ISkpibJly3L58mXatm3L/PnzCQkJ8XZYhc7V76CIRBtjmua0rXa5FAGZ/mD5/y3zm+rekad9v9WvR7rl51ZuyNN+lGt7j1/MtM5Wq6IXIin+hg4dyoEDB7h69SoDBw68KZN5fmlCV0qxePFiZs6cmW5dq1atmDMn81VtQXn//fcL7VhWpQldKcXgwYMZPHiwt8NQ+aQ3RZVSyiJu+hZ6xj5mKL79zHOGbfJ2CMqF/ef2Z1pX73TmwQilAwIKIxxlYdpCV0opi7jpW+hKZWtyhWxftrmxi8Zpvt8/6tt8haNUdrSFrlQREh8fT4AHul6WLFnCyZMnncvvvvsuly9fzvd+i4ubtV67JnSliohfj/3OueOJJF+/wa/Hfs/XvvKb0FNSUvJ1/KJq2LBhPPbYY94Oo8BoQleqiLmRksKz40fTuHFjunbtyv79+9M9ZHP48GHn8pQpUwgLCyMgIIChQ4dijGHNmjVERUUxYMAAgoODmTlzJidPnqRDhw7OGY9cKVu2LM899xxBQUHs3LmT6Oho2rVrR2hoKN26dePUqVMAREZGYrPZCA4OZty4cc4ripSUFMaNG0dYWBg2m4158+YB9oJj7du3p0+fPjRo0IABAwaQ+oR6ZGQkLVu2JCgoiGbNmpGYmEjbtm2JiYlxxtW6dWtiY2Ndxqz12tPThK5UEfNT/FEef3QI+/fvp2LFinz//fdUqFDBmeQWL17sHDM+atQoIiMj2bdvH1euXGHDhg306dPHWT89JiaGsWPHcuutt7J58+Zsa7FcunSJ8PBwYmNjCQ8PZ/To0axZs4bo6Ggef/xxJk6cCNjHrM+bN4+YmBh8fX2d2y9cuJAKFSoQGRlJZGQkCxYs4L///S8A33//Pe+++y4HDhzgp59+YseOHVy7do1+/foxc+ZMYmNjiYiIoHTp0jzxxBMsWbIEgEOHDnH16lWCgoJcxqz12tPThK5UEXPH7bUJaGy/3RoaGkp8fDxPPvkkixcvJiUlhZUrV/K3v9nLQ2zevJnw8HACAwPZtGkT+/dnHiLpLl9fXx566CEAfvzxR/bt20eXLl0IDg5m2rRpHD9+nIsXL5KYmEiLFi0AnHEAfPnllyxbtozg4GDCw8M5f/68s5Z7s2bNqFWrFj4+PgQHBxMfH8+PP/5IzZo1CQsLA6B8+fKUKFGCvn37smHDBq5fv86iRYsYNGhQljFHREQwcuRI53JW9drj4+PTbeeqXnuZMmUwxjBhwgRsNhudO3d2Wa+9XLly2dZr37p1a55+/p6go1yUKmJKlizl/N7X15crV67w0EMP8corr9CxY0dCQ0OpUqUKV69eZcSIEURFRXH77bczefLkfNUW9/f3d7a4jTE0btyYnTt3pnvPxYuZa9ekMsYwe/ZsunXrlm79li1bnDXaU88pu/rpZcqUoUuXLnz88cesWrWK6OjoXJ+LJ+q1+/n5UadOnWJVr714JnRXQ8nyWLxKFayMhceg8GuM58vkhGxfdqc4l6sHi3LL39+fbt26MXz4cBYuXAjgTDRVq1YlKSmJNWvW0KdPH8BejzwxMdG5fepyTuVyU9WvX5+zZ8+yc+dOWrRowfXr1zl06BCNGzemXLlyfPfdd4SHh6ebzahbt2689957dOzYET8/Pw4dOuSsu57VMU6dOkVkZCRhYWEkJiZSunRpSpQowZNPPskDDzxAmzZtsq2/rvXa09MuF6WKiQEDBuDj40PXrl0BqFixIkOGDCEgIIBu3bo5uy4ABg0axLBhwwgODubKlSsMHTqU7t27Z3tTNK2SJUuyZs0aXnjhBYKCgggODubbb+1j6BcuXMiQIUMIDg7m0qVLzrrlTz75JI0aNSIkJISAgACeeuqpbFvGJUuWZOXKlYwePZqgoCC6dOni/CMVGhpK+fLlc6wvo/Xa0yue9dBdlJcNdNFCd6ce+tULb2daV9iP/hfm+Xn73KBot9BzWw89ry10V4/+J5ZL/xnfUrt8uuUZM2aQkJDA1KlT3Y6vIKTWLQeYPn06p06dylSpMb9OnjxJ+/btiYuLw8enaLQ7C6teu9ZDV8rievfuzdGjR9m0yfv1ejZu3Mhrr71GcnIytWvXdo5I8ZRly5YxceJE3n777SKTzKF41GvXhK6KhIwzMmW8+oCbe0am9evXe2xf4eHh/PHHH+nWLV++nMDAzLNiudKvXz/69evnsXgyeuyxxzI9/KP12t3jdkIXEV8gCjhhjOkhInWBD4EqQDTwqDHmWsGEqZTylO+++87bIeSa1mt3T26uZ8YCaZtIrwPvGGPuAi4AT3gyMKWUUrnjVkIXkVrA/cD/OpYF6AiscbxlKdCrIAJUSinlHndb6O8CzwM3HMtVgIvGmNSOzuNA1gNOlVJKFbgc+9BFpAfwqzEmWkTa5/YAIjIUGApwxx368I/KO1czMo2c27FAj5nxZm1+fXj/hzm+5/6/dmHjuq84ffRwptdq3Hk3YK+eOHToUMqUKePR+NyV8fj33Xcf77//PhUrVsxhS/fFx8fz7bffpisvkNX7evTowb59+3K1/zp16hAVFZXpYatPPvmEAwcOMH78+FzH7G3utNBbAT1FJB77TdCOwEygooik/kGoBZxwtbExZr4xpqkxpmm1atU8ELJS1rZx3Vc5vicv9c09WRI34/E/++wzjyZzsCdqb4ws6dmzZ7FM5uBGQjfGvGiMqWWMqQM8AmwyxgwANgN9HG8bCHycxS6UUrlQt9GtAHy76zv++re/8+TI0bTu2o0Rz9or/82aNStTOdwvv/ySFi1aEBISQt++fUlKSgLsrdAXXniBkJAQVq9e7bJkrDHGWQY3MDCQlStXAlmXvXV1/Dp16nDu3Dni4+Np2LAhQ4YMcZb/vXLlCgBHjx6le/fuhIaG0qZNG+Li4gD7U61jxoyhZcuW1KtXjzVr7Lfmxo8fz7Zt2wgODuadd94hPj6eNm3aEBISQkhIiPPJ1ZykpKTwj3/8g4CAAGw2G7Nnz3a+Nnv2bGep3NR4lixZwqhRowA4c+YMvXv3JigoiKCgIOcxe/XqRWhoKI0bN2b+/PnO/S1cuJB77rmHZs2aMWTIEOd+4uPj6dixIzabjU6dOvHzzz/n6nfCXfkZtf8C8KyIHMHep77QMyEppVLtO3CAKS9NZOt/Pufnn39hx44djBkzJl053HPnzjFt2jQiIiLYs2cPTZs25e23/3xCuEqVKuzZs4dHHnnEZcnYdevWERMT4yxhO27cOGftc1dlbzMeP6PDhw8zcuRIZ/nf1BrlQ4cOZfbs2URHRzNjxgxGjBjh3ObUqVNs376dDRs2OFvH06dPp02bNsTExPDMM89wyy238NVXX7Fnzx5WrlzJmDFj3PoZzp8/n/j4eGJiYti7dy8DBgxwvla1alX27NnD8OHDnfXN0xozZgzt2rUjNjaWPXv20LixfULBRYsWER0dTVRUFLNmzeL8+fOcPHmSqVOnsmvXLnbs2OH8AwEwevRoBg4c6Dy+u7HnVq4eLDLGbAG2OL7/CWjm+ZCUUqmaBNm4tWYNABo3akh8fDytW7dO955du3Zx4MABWrVqBcC1a9ec5W0B50NArkrGAmzfvp3+/fvj6+tL9erVadeuHZGRkZQvX95Z9hZwlr3NePyM6tatS3BwMPBn6dqkpCS+/fZb+vbt63xf2oebevXqhY+PD40aNXJORpHR9evXGTVqlLMO+6FDh3L46dlFREQwbNgwSpSwp7vKlSs7X2vQvBN7j1+k/O33sO+DVZm23bRpk3PKOl9fX2f9llmzZjkf9vrll184fPgwp0+fpl27ds799+3b1xnjzp07WbduHQCPPvoozz//vFux55Y+KapUEVayZEnn974+Pi6LXRlj6NKlCx988IHLffzlL3/J8/FzU/Y2q22uXLnCjRs3qFixYrqZiLLaJqv6Uu+88w7Vq1cnNjaWGzduOP8g5UdJx3F9fXxJcbPE7pYtW4iIiGDnzp2UKVOG9u3bF5kSu0WnUIJSym1py+M2b96cHTt2cOTIEcA+W4+r1mvakrFgbyFfvnyZNm3asHLlSlJSUjh79ixbt26lWbPsL74zlufNSfny5albty6rV68G7Ek7q2nlsjpGQkICNWvWxMfHh+XLl7t9k7dLly7MmzfP+cfot99+czvuTp068d577wE4y+smJCRQqVIlypQpQ1xcHLt27QLsFRm/+eYbLly4QHJycrrp8Fq2bOksNbxixQratGnjdgy5oS10pbLxw8Afsn3dZbVFn/+mW96fppXtKanlcFP7spcsWUL//v2d3RjTpk3jnnvuybTd8uXLeeqpp5g0aRJ+fn6sXr2a3r17s3PnToKCghAR3njjDWrUqJGuDzin47tjxYoVDB8+nGnTpnH9+nUeeeSRLKeWA7DZbPj6+hIUFMSgQYMYMWIEDz30EMuWLaN79+5uX3k8+eSTHDp0CJvNhp+fX7qblTmZOXMmQ4cOZeHChfj6+vLee+/RvXt35s6dS8OGDalfvz7NmzcH4LbbbmPChAk0a9aMypUr06BBA2cXzezZsxk8eDBvvvkm1apVY/HixW4dP7e0fK6Wzy1Q7pbPdac4l6vz8/Q4dI+Uz3UjobtTPvdGcua+5NRx6MozMn5+GUsf51Zqid3k5GR69+7N448/7rxn4a78lM/VLhellPKQyZMnExwcTEBAAHXr1qVXr8KtiKJdLkopS/jiiy944YUX0q2rW7euR0sP58TV0MfCpAldKWUJ3bp1yzRB9c1Gu1yUUsoitIWuCt/kCpnXubjp6463+vVIt1zYN32VKkq0ha6UUhahCV0ppSxCu1yUysbBBtmPSfdztU2G5bStphvb1+CO+//ahU9X/Z9b7y1sgwYNokePHvTp0yfd+pMnTzJmzBhntURV+LSFrlQR5E5N9KLm1ltv1WTuZZrQlSqC6ja6lUuXLtH30cfo0rMXHe7rwX++igDstbUbNGjAoEGDuOeeexgwYAARERG0atWKu+++m927dwP2mi6PP/44zZo1o0mTJnz8sX3Kgv3799OsWTOCg4Ox2WwcPpx5ZqRUy5Ytw2azERQUxKOPPupcv3Xr1kz1y+Pj4wkICACyrkE+ZcoUwsLCCAgIYOjQoc5CXJGRkdhsNoKDg5212QGuXr3K4MGDCQwMpEmTJm6XGbhZaUJXqogqVaoUi/7nf/jqk49Y83/LeOW16c4EeOTIEZ577jni4uKIi4vj/fffZ/v27cyYMYNXX30VgH/961907NiR3bt3s3nzZsaNG8elS5eYO3cuY8eOJSYmhqioKGd53Iz279/PtGnT2LRpE7GxscycOdP5mqv65WllVYN81KhRREZGsm/fPq5cucKGDfZRSYMHD2bevHnO0rip5syZg4jwww8/8MEHHzBw4MAiU9mwKNKErlQRZYzhtbfeouP9D9Bv4CBOnznjrBVet25dAgMD8fHxoXHjxnTq1AkRITAwkPj4eMA+i9H06dMJDg52lnj9+eefadGiBa+++iqvv/46x44do3Tp0i6Pv2nTJvr27eucczNtHfGc6pdHRETw1FNPZapBvnnzZsLDwwkMDGTTpk3s37+fixcvkpiY6KzhnnYO0e3bt/P3v/8dgAYNGlC7dm2366DfjPSmqFJF1LpPPuX8b7/xxUfr8PPzI6xdB2frNG39cB8fH+eyT5qa6cYY1q5dS/369dPtt2HDhoSHh7Nx40buu+8+5s2bR8eOuSty5k798oyuXr3KiBEjiIqK4vbbb2fy5Mna2vYwbaErVUT9nphI1SpV8PPzY8fOXRw/4XIe9ix169aN2bNnOxPu999/D8BPP/1EvXr1GDNmDA8++CB79+51uX3Hjh1ZvXo158+fB3JXR9xVDfLU5F21alWSkpKcfe8VK1akXLlyfPfddwDOuuEAbdq0YcWKFQAcOnSIn3/+OdMfKG+4sm9fui9XTh89nOmroGkLXalsNIzLOAgxvYKqhy4i/LXnAwwcOowO9/UgKDCAu+6sl6t9/POf/+Tpp5/GZrNx48YN6taty4YNG1i1ahXLly/Hz8+PGjVqMGHCBJfbN27cmIkTJ9KuXTt8fX1p0qQJS5YscevYWdUgHzJkCAEBAdSoUYOwsDDn+xcuXMiQIUPw8fGhXbt2zjriI0aMYPjw4QQGBlKiRAmWLFmS7upApacJXaki5rcLv1GpYiWqVK7MhjXp57msUacOAPvStArTJtk6deo4XytdujTz5s3LtP/x48e7vJHpysCBAxk4cGC6dRmTelJSUqZjlyhRgrfffjvdZNVgn3hj2rRpmY7TuHFj55XC9OnTadrUXvrb39+/wCaDsCJN6EoVIafPnKL3I/czfMhob4dSqDZu3Mhrr71GcnIytWvXdvtKQKWnCV2pIqRG9Zrs3LwHcD1jUUE4f/48nTp1yrT+66+/pkqVKoUSQ79+/ejXr1+hHCu39p/bn2ldxs6vX4/9XjjB5EATulI3uSpVqhATE+PtMJQH6CgXpZSyCE3oSillEZrQlVLKIjShK6WURehNUaWyMWfYplxvsy2b19pPq573YLIwadIk2rZtS+fOnfO9r5iYGE6ePMl9992X7fu2bNnCjBkznMW13FW2bFnnuPW05s6dS5kyZXjsscdytT+VniZ0pYq5KVOmeGxfqRUYc0ronjZs2LBCPZ5VaZeLUkXIpcuXGDC4Lx26t6L9vffz73nzeXzESAD+81UEpUuX5tq1a1y9epV69eyjoQcNGuSsizJ+/HgaNWqEzWbjH//4BwCrV68mICCAoKAg2rZtC7iuM37t2jUmTZrEypUrCQ4OZuXKlVnWVM9JUlKSc/82m421a9c6X5s4cSJBQUE0b97cWalx8uTJzJgxA7CXBu7cuTNBQUGEhIRw9OhRkpKS6NSpEyEhIQQGBqaLY+rUqdSvX5/WrVvTv39/535iYmJo3rw5NpuN3r17c+HChTx/LsWFttCVKkI2fxNB9eo1WLF4NTeSz/B7YiLLHcWqvouKIiAggMjISJKTkwkPD0+37fnz51m/fj1xcXGICBcv2uvMTJkyhS+++ILbbrvNuS5tnfG4uDi6du3KoUOHmDJlClFRUfz73/8GYMKECXTs2JFFixZx8eJFmjVrlqlrx9WDN8veXEaFChX44YcfALhw4QK/HvudS5cu0aCejbGfvMCMOdNYsGABL730UrptBwwYwPjx4+nduzdXr17lxo0blCxZkvXr11O+fHnOnTtH8+bN6dmzJ1FRUaxdu5bY2FiuX79OSEgIoaGhADz22GPMnj2bdu3aMWnSJF555RXefffd/H5ERZq20JUqQhrWb8zWbVuY+tokdkVGUr5cOerccQeHjhzh+717efbZZ9m6dSvbtm2jTZs26batUKEC/v7+PPHEE6xbt44yZcoA0KpVKwYNGsSCBQtISUkB3K8znlVN9ZxEREQwcuRI53KlSpUAKFmyJF07dQcgNDTUWbs9VWJiIidOnKB3796AvZZLmTJlMMYwYcIEbDYbnTt35sSJE5w5c4YdO3bw4IMP4u/vT7ly5XjggQcASEhI4OLFi7Rr1w6w16TZunVrjnEXd9pCV6oIubPeXXy18Ru+3vwVr7/9Lm1atiA8LIxN32zFr0QJOnfuzKBBg0hJSeHNN99Mt22JEiXYvXs3X3/9NWvWrOHf//43mzZtYu7cuXz33Xds3LiR0NBQoqOj3Y4nq5rqria1cEeJEn6ICAC+vr7O8ro5WbFiBWfPniU6Oho/Pz/q1KmjtdRd0Ba6UkXI6TOnKO1fhj69+zFiyJPs3b+f5k2bsmDJUkKbNKFatWqcP3+eH3/80TnvZqqkpCQSEhK47777eOedd4iNjQXg6NGjhIeHM2XKFKpVq8Yvv/ySZZ3xcuXKkZiY6NxnVjXVc9KlSxfmzJnjXHa3/7pcuXLUqlWLjz76CIA//viDy5cvk5CQwC233IKfnx+bN2/m2LFjgP3q49NPP+Xq1askJSU5R91UqFCBSpUqsW2bfczR8uXLna11K9MWulLZGDk3+5l8PF0P/WDcfl55bRI+4kOJEobpU16h/t132/uNHfXDbTYbp0+fdrZ0UyUmJvLggw9y9epVjDHO0rXjxo3j8OHDGGPo1KkTQUFBNGjQwGWd8Q4dOji7WF588cUsa6rn5KWXXmLkyJEEBATg6+vLyy+/TOtQ94ZVLl++nKeeeopJkybh5+fH6tWrGTBgAA888ACBgYE0bdqUBg0aABAWFkbPnj2x2WxUr16dwMBAZy31pUuXMmzYMC5fvky9evVuijK8OSZ0EfEHtgKlHO9fY4x5WUTqAh8CVYBo4FFjzLWCDFYpq+vQrjMd2tkTX9pqi8cO/nnjcf78+em2SVtqdvfu3Zn2uW7dukzrsqozXrlyZSIjI9Otc1VTvX379rRv3971SWAfb7506dJ063499jv/PXDSudynTx/69OkD2Ee5pLr77rvZtCnz+P+dO3e6PNY//vEPJk+ezOXLl2nbtq3zpmhwcDC7du3KMkYrcqfL5Q+gozEmCAgGuotIc+B14B1jzF3ABeCJggtTKaVcGzp0KMHBwYSEhPDQQw8REhLi7ZC8JscWurF3nqU+2uXn+DJARyB1eu6lwGTgPc+HqJQqqhYvXszrb72ebl2TZk34YNEHhRbD+++/X2jHKurc6kMXEV/s3Sp3AXOAo8BFY0zqLerjwG0FEqFSqsgaPHgwzR5o5u0wlINbCd0YkwIEi0hFYD3QwN0DiMhQYCjAHXfckZcYlVLFzJU0c546lSsG//9PuhjFk4dJvr0lV8MWjTEXgc1AC6CiiKT+QagFnMhim/nGmKbGmKbVqlXLV7BKKaWylmNCF5FqjpY5IlIa6AIcxJ7Y+zjeNhBwr8iDUkqpAuFOl0tNYKmjH90HWGWM2SAiB4APRWSV1QNOAAAbnklEQVQa8D2wsADjVEoplQN3RrnsBZq4WP8ToHdDlKW91a9Hrrf5KpvXus95PZtXISHhIus+Wc3gR4fw7a7veG/hQpYvmJ/tNp6W11rneTVo0CB69OjhHJPuTZPfmkvZv5ThH8My12UfcN8AVny2ghM/n+DhfiOJWr+e2Lg4Tv36K63u/7sXos1MH/1XqghJ+D2BxcutebHrbt2WomrFZysyrdsbF8cX27Kb0qRwaUJXqgiZ9vpkjh37Lx3vbc2U11/n0qXLPDlyNK27dmPEs885a6pER0fTrl07QkND6datG6dOncpyn+3bt2fs2LEEBwcTEBDgfJp09+7dtGjRgiZNmtCyZUt+/PHHTNtOnjyZgQMH0qZNG2rXrs26det4/vnnCQwMpHv37ly/fh2A/bH7GdRzEA93epihfYdy6uxZALoNHsy411+nVb9+LFic9WMqW7dupWXLltSrV89Z290Yw7hx4wgICCAwMJCVK1cC9iuIHj3+vHIaNWqU82lZV/Xgz549y0MPPURYWBhhYWHs2LEj28/gwKGfaN9nCPVaPMCshX+Opw+rHZbufdeuX2fqnDms/eILOt7bmo8+XcuFi78xcMjfaN+9Jfc/1JcDcXEAzJg5i2fGv0j79u2pV68es2bNyjaGvNJaLkoVIS+9MJm4QwfZ9Pl2tm//hEHDhrPl88+oUf0Wej78CDt27CA8PJzRo0fz8ccfU61aNVauXMnEiRNZtGhRlvu9fPkyMTExbN26lccff5x9+/bRoEEDtm3bRokSJYiIiGDChAnpJqJIdfToUTZv3syBAwdo0aIFa9eu5Y033qB3795s3LiROuF1ePXFV5m9bDaVq1bm8/WfM3nWLOZNnQrYE9+OlStJzGbY4qlTp9i+fTtxcXH07NmTPn36sG7dOmJiYoiNjeXcuXOEhYU5J+hwJat68GPHjuWZZ56hdevW/Pzzz3Tr1o2DBw9muZ+4I/FsXj2fxEuXqN/mr7R98m/4+fllel9JPz/+OXIke/bvZ8p0e3mEF18eR2BjG0sXvM/WbR8xZtzzRHz6CQBHjv7E9p07SUxMpH79+gwfPtzlfvNDE7pSRViTIBu31qwBQONGDYmPj6dixYrs27ePLl26AJCSkkLNmjWz3U///v0BaNu2Lb///jsXL14kMTGRgQMHcvjwYUTE2drO6N5778XPz4/AwEBSUlLo3t1ezzwwMNBez7wKHDl4hCF9hgBw48YN7qhY1bl9n27dcjzPXr164ePjQ6NGjZylebdv307//v3x9fWlevXqtGvXjsjISMqXL+9yH2nrwffo0cPZio+IiODAgQPO9/3+++8kJSVRtmxZl/u5v1NrSpUqSalSJbmlaiXOnz1PjVtr5HgOALsjd7Jw7nIAWrdowYULF0lMtD9o36lDe0qVKkWpUqW45ZZbOHPmDLVq1XJrv+7ShK5UEVYyzUMtvj4+JCcnY4yhcePGWRarciVjZUYR4Z///CcdOnRg/fr1xMfHZ1lsq1SpUgD4+Pjg5/dnPXOfNPHc1eAuVnz+Zx9zvdPG+X3qRBvZST0G4OxWykqJEiW4ceOGczm1LnpW9eBv3LjBrl278Pf3zzEOeyxpfua+vqQkp7i1XY77LZl+vwVxT0H70JUqQsqWLcelS0nZvqd+/fqcPXvWmdCvX7/O/v2Zp4FLK7X/efv27VSoUIEKFSqQkJDAbbfZK3akrdiYW3Xvqstv534jJjLGGc+BI0fyvL9Ubdq0YeXKlaSkpHD27Fm2bt1Ks2bNqF27NgcOHOCPP/7g4sWLfP3110DW9eC7du3K7NmznfuNiYnJd2ypyv3lLyRdvuxcDm/WknUfrQbg213fUblSJcqVc30lUBC0ha5UNp5bmf3QPU/XQ69cqTJhoeG07doc/1K+VKtaNdN7SpYsyZo1axgzZgwJCQkkJyfz9NNP07hx4yz36+/vT5MmTbh+/bqzr/35559n4MCBTJs2jfvvv9/tGDPyK+nHO4ve4bUJr5GYmEhKcgrPPPJ3Gt11V573CdC7d2927txJUFAQIsIbb7xBjRr2ro+HH36YgIAA6tatS5Mm9lHVWdWDnzVrFiNHjsRms5GcnEzbtm2ZO3duvmJL1bZZM2YsXEjHe1szZsQzjHt6PE+PG0X77i0pXaoEM9/Mfpiqp0lOlzee1LRpUxMVFZXr7eqM35huOd7/b5neE1g38w2XVa+lv6TZ1H5OpvdcvfB2pnU5/Sf2tMI8P2+fG7h3fhnPDQrn/A4ePEjDhg3dfn9eE3raLolUGW8apq2HnqrGnXe7HVuq9u3bM2PGDJo2bZrrbd3hapJod87vltqu+8ILU8bPL+NnB+59fq5u+Ob183P1Oygi0caYHD9AbaErpXInYwGrYlS8yuo0oStlESNHjsw0xnrs2LFs2bLFOwFl8M6/3+TTjX+WfCpR0oe+ffsyceLEQo9l8eLFzJw5k6vX/7zhGdw0nA9fG1nosXiSJnSlLCLtpMxF0TOjxvHMqHHOZW92uQwePJjBgwe76DLL3OVSnOgoF6UyKMz7Skqlld/fPW2hK5WGv78/58+fp0qVKpnGbivPOn30cKZ1ebnpaxXGGM6fP+/2eHlXNKErlUatWrU4fvw4Zx21SHJy5sKVTOsOSvptT5fI/N8s5ffM+7p6Mf2TmuZG5jdduFYEClxd/DXdYnE+v4yfX8bPDtw7v4znBnk7P39//3w9PaoJXak0/Pz8qFu3rtvvv9eNYZkPuzHkFGBbhmGZRWFIrUuTm6dbLM7nl/HzczWk1p3zy3hu4J3z0z50pZSyCE3oSillEdrlopTKkusnfb0QiHKLttCVUsoiNKErpZRFaEJXSimL0ISulFIWoQldKaUsQhO6UkpZhCZ0pZSyCE3oSillEZrQlVLKIjShK6WURWhCV0opi9CErpRSFqEJXSmlLEITulJKWYQmdKWUsghN6EopZRGa0JVSyiJyTOgicruIbBaRAyKyX0TGOtZXFpGvROSw499KBR+uUkqprLjTQk8GnjPGNAKaAyNFpBEwHvjaGHM38LVjWSmllJfkmNCNMaeMMXsc3ycCB4HbgAeBpY63LQV6FVSQSimlcparPnQRqQM0Ab4DqhtjTjleOg1U92hkSimlcsXthC4iZYG1wNPGmN/TvmaMMYDJYruhIhIlIlFnz57NV7BKKaWy5lZCFxE/7Ml8hTFmnWP1GRGp6Xi9JvCrq22NMfONMU2NMU2rVavmiZiVUkq54M4oFwEWAgeNMW+neekTYKDj+4HAx54PTymllLtKuPGeVsCjwA8iEuNYNwGYDqwSkSeAY8DDBROiUkopd+SY0I0x2wHJ4uVOng1HKaVUXumTokopZRGa0JVSyiI0oSullEVoQldKKYvQhK6UUhahCV0ppSxCE7pSSlmEJnSllLIITehKKWURmtCVUsoiNKErpZRFaEJXSimL0ISulFIWoQldKaUsQhO6UkpZhCZ0pZSyCE3oSillEZrQlVLKIjShK6WURWhCV0opi9CErpRSFqEJXSmlLEITulJKWYQmdKWUsghN6EopZRGa0JVSyiI0oSullEVoQldKKYvQhK6UUhahCV0ppSxCE7pSSlmEJnSllLIITehKKWURmtCVUsoiNKErpZRF5JjQRWSRiPwqIvvSrKssIl+JyGHHv5UKNkyllFI5caeFvgTonmHdeOBrY8zdwNeOZaWUUl6UY0I3xmwFfsuw+kFgqeP7pUAvD8ellFIql/Lah17dGHPK8f1poLqH4lFKKZVH+b4paowxgMnqdREZKiJRIhJ19uzZ/B5OKaVUFvKa0M+ISE0Ax7+/ZvVGY8x8Y0xTY0zTatWq5fFwSimlcpLXhP4JMNDx/UDgY8+Eo5RSKq/cGbb4AbATqC8ix0XkCWA60EVEDgOdHctKKaW8qERObzDG9M/ipU4ejkUppVQ+6JOiSillEZrQlVLKIjShK6WURWhCV0opi9CErpRSFqEJXSmlLEITulJKWYQmdKWUsghN6EopZRGa0JVSyiI0oSullEVoQldKKYvQhK6UUhahCV0ppSxCE7pSSlmEJnSllLIITehKKWURmtCVUsoiNKErpZRFaEJXSimL0ISulFIWoQldKaUsQhO6UkpZhCZ0pZSyCE3oSillEZrQlVLKIjShK6WURWhCV0opi9CErpRSFqEJXSmlLEITulJKWYQmdKWUsghN6EopZRGa0JVSyiI0oSullEXkK6GLSHcR+VFEjojIeE8FpZRSKvfynNBFxBeYA9wLNAL6i0gjTwWmlFIqd/LTQm8GHDHG/GSMuQZ8CDzombCUUkrlVn4S+m3AL2mWjzvWKaWU8gIxxuRtQ5E+QHdjzJOO5UeBcGPMqAzvGwoMdSzWB37Me7i5VhU4V4jHK2xWPj8rnxvo+RV3hX1+tY0x1XJ6U4l8HOAEcHua5VqOdekYY+YD8/NxnDwTkShjTFNvHLswWPn8rHxuoOdX3BXV88tPl0skcLeI1BWRksAjwCeeCUsppVRu5bmFboxJFpFRwBeAL7DIGLPfY5EppZTKlfx0uWCM+Qz4zEOxFASvdPUUIiufn5XPDfT8irsieX55vimqlFKqaNFH/5VSyiI0oSullEVoQldKKYuwbEIXkUoiYvN2HMp9InKniJRyfN9eRMaISEVvx+VJIlJbRDo7vi8tIuW8HZOniMhbItLY23HczCyV0EVki4iUF5HKwB5ggYi87e24PElE7hGRBSLypYhsSv3ydlweshZIEZG7sI8iuB1437sheY6IDAHWAPMcq2oBH3kvIo87CMwXke9EZJiIVPB2QJ4iItVFZKGIfO5YbiQiT3g7rowsldCBCsaY34G/AsuMMeFAZy/H5Gmrsf+xegkYl+bLCm4YY5KB3sBsY8w4oKaXY/KkkUAr4HcAY8xh4BavRuRBxpj/Nca0Ah4D6gB7ReR9Eeng3cg8Ygn2Z25udSwfAp72WjRZsFpCLyEiNYGHgQ3eDqaAJBtj3jPG7DbGRKd+eTsoD7kuIv2Bgfz5+fl5MR5P+8NRmRQAESkBWGrcsKOsdgPH1zkgFnhWRD70amD5V9UYswq4AfYHK4EU74aUmdUS+hTsf0WPGGMiRaQecNjLMXnapyIyQkRqikjl1C9vB+Uhg4EWwL+MMf8VkbrAci/H5EnfiMgEoLSIdMF+tfWpl2PyGBF5B4gD7gNeNcaEGmNeN8Y8ADTxbnT5dklEquD4AywizYEE74aUmT5YVMyIyH9drDbGmHqFHozKFRHxAZ4AugKCvfHxv8Yi/wlFZDCwyhhzycVrFYwxRS4BuktEQoDZQACwD6gG9DHG7PVqYBlYKqGLyBvANOAK8B/ABjxjjPk/rwam3CIiPYCpQG3sZSkE+x+r8l4NzENE5C/AVWNMimPZFyhljLns3cg8Q0S+NsZ0ymldceXoIquP/ffyR2PMdS+HlEm+arkUQV2NMc+LSG8gHvvN0a2AZRK6iPgBw4G2jlVbgHlF8ZcrD97F/pn9YJVWawZfY79Jn+RYLg18CbT0WkQeICL+QBmgqohUwp7wAMpjkUlvROSxDKtCRARjzDKvBJQFqyX01PO5H1htjEkQkezeXxy9h/1G4f84lh91rHvSaxF5zi/APosmcwB/Y0xqMscYkyQiZbwZkIc8hX3Ex63YR2Cl+h34t1ci8rywNN/7A52wn6sm9AK0QUTisHe5DBeRasBVL8fkaWHGmKA0y5tEJNZr0XjW88BnIvIN8EfqSmOMVZ4luCQiIcaYPQAiEor9d7VYM8bMBGaKyGhjzGxvx1MQjDGj0y47HngrciN3LJXQjTHjHf3oCcaYFBG5jPUmrk4RkTuNMUcBHCN5itzwqTz6F/buCH+gpJdjKQhPA6tF5CT2bokaQD/vhpR/ItLRGLMJOCEif834ujFmnRfCKmiXgLreDiIjSyV0x+XrCOAO7POY3or9JoaVxqSPAzaLyE/Yk0Jt7MP9rOBWY0yAt4MoKI6htA2w/05CEb2xlgftgE3AAy5eM0CxT+gi8il/PjPgAzQCVnkvItesNsplJRANPGaMCXAk+G+NMcFeDs2jHPVO0iaFP7J7f3HhuLqKMMZ86e1YPCm1Beuq9QqWbcFaioi0S7OYDBwzxhz3VjxZsVpCjzLGNBWR740xTRzrYjP0ORdLN0NSEJFE4C/ANSC15Vrshy2KyCvGmJdFZLGLl40x5vFCD8qDROTZ7F630D2QIs9SXS7ANREpzZ9Pc91JmptrxZzlL2uNMZapPJiWMeZlx7dPpo5BtxhLfm7gbGS4avUWyWckrNZC74K9aFUj7ON7WwGDjDFbvBmXJ4lIXWPMf3NaV1yJSE/SjLE3xljm/oeI/Iz9gbeVwCYLD89UXmKphA7gqLfQHPtf0F3GmHNeDsmjRGSPMSYkw7poY0yot2LyFBGZjn287wrHqv5AlDHmRe9F5TmOezo9gEeAEOw36z80xmz3amAe4njA6AmgMfaRSgAU9y6ltETkFtKf289eDCcTq3W5gP2HfQH7uTVyPM211csx5ZtjdERjoEKGfvTypPkFK+buA4KNMTcARGQp8D1giYTueMR/FbDK8UTlTOAbwNergXnOcuzFubphL5Q3AHuN9GLPceX4FvaRc79iH112EPv/ySLDUgldRF7HPq53P44yl9j7v4p9Qsc+qqUHUJH0/eiJwBCvRFQwKgK/Ob63zAQJqRyjJfoB3YEo7KWereIuY0xfEXnQGLNURN4Htnk7KA+Ziv3KP8IY08RR4/3vXo4pE0sldKAXUN8qw/jSMsZ8DHwsIi2MMTu9HU8BeQ34XkQ2Y+8yawuM925IniMi8divOFYB41xVJSzmUkcmXRSRAOA01pnA47ox5ryI+IiIjzFms4i86+2gMrJaQv8Je50TyyX0NL4XkZFYsJ/SGPOBiGzhz7oZLxhjTnsxJI9xVFZcZIyZ4u1YCtB8R1fSP4FPgLLAJO+G5DEXRaQs9iuOFSLyK/anRYsUqyX0y0CMiHxN+logY7wXksdZtp/SIYw/R7kYLDIBhKMURQ/sn5klGWP+1/HtN4DV6vNvxt4FOBZ7V0sFiuBnaalRLiIy0NV6Y8zSwo6loKQ+NCUie40xNkc53W3GmObeji2/shjlEmmMmeC9qDzHMaOPH/Zhi87WXWqxruJORFy2xq1wVSIiL2O/3/Eb9s9vtTHmjHejysxSCf1mICK7jTHNRGQr9ro1p4HdVpixSET2kn6Uiy/wvTHG5t3IPMNxbyAjY4zpWOjBFAAReS7Noj/2m/gHrdAdmEpEbNhvaj8EHDfGFKlJ6C3R5SIiq4wxD4vID7h4qssqCcEhtZ/yJazXTwkWHuVijOng7RgKkjHmrbTLIjID+zR7VvIr9kbUeYrgDV9LtNBFpKYx5pSI1Hb1ujHmWGHHpHJH7DORPIp9eFi6US7GmJXejM1TRKQ68Cr2qpL3ikgjoIUxZqGXQysQjoZHpDHmLm/Hkl8iMgJ7l0s17JN7rzLGHPBuVJlZIqHfTETkVeANY8xFx3Il4DljzEvejSz/HFdYXflzlMtuq4xyARCRz4HFwERjTJBjjsrvjTGBXg7NIzJcIftiT35TjDHFftYiEXkNWGmMifF2LNmxREIvbgV08iNtJck06zKVAyiOHE+G/tsYE+ntWAqCiEQaY8IyVAONsUp55wxXyMnAGWNMsrfiuRlZog/dqlX6suArIqVSH55yVJcs5eWYPCUcGCAix7CPAkn9g2yVeyCXHLWGUquBNgcSvBuSRyVmWC6fdk5fY8xvqAJliYSelmNkRHXSnFtRK6CTTyuAr9PU1h4MWGVYZjdvB1DAnsV+I/tOEdmBvUuij3dD8qg9wO3YaykJ9hvcqf/3DNYbm17kWCqhi8ho4GXgDOlruVilhYcx5nXHpNCpw6WmGmMsMZLgJrh5fSdwL/ak9xD2KxIr/R/8ClhvjPkMQETuBXoZY57yblg3D0v0oacSkSNAuDHmvLdjKUiO0RLNsP+x2m2M+dXLISk3pHkYrDX20TwzgEnGmHAvh+YRIvJDxhu8rtapguPj7QA87Bes1SeZiYg8DOzGfqn+MPCdiFjpst3KUmcruh9YYIzZCJT0YjyedlJEXhKROo6vicBJbwd1M7FaC30h9jKzG0lfy8Uycxo6ulu6pLbKRaQa9pKexX7eVKsTkQ3ACaAL9gkurmC/wrLEZycilbF3eabW4tkKvKI3QwuPlfrvwH4D5mfsrR4rtXzS8snQxXIe611pWdXD2OugzzDGXBSRmsA4L8fkMY7EPVZEKgA3jDEZR72oAmapFvrNQETexH6T9wPHqn7AXmPMC96LSikQkTBgEX9OGp0APG6MifZeVDcXSyV0R/fD82SuFW6J4kepROQh7BNgg73S4npvxqMUOIurjTTGbHMstwb+x0LPERR5VutyWYG9tGUPYBgwEDjr1YgKgDFmLbDW23EolUFKajIHMMZsFxF9UrQQWa2FHm2MCU0dHuZYF2mMCctp26LuZipvoIonx5RspbF3Bxrs3YFXgf8D69R9L8qs1kJPndPwlIjcj33IVGUvxuMxN1l5A1U8pY7WeTnD+ibYE7yluj6LIqu10Htgn/PvdmA2UB77sKlPvBqYUkoVAksldKWU99xs9d6LIkuNXxaRe0TkaxHZ51i2iUixrxOuVDGxBPsMRbc6lg8BT3stmpuQpRI6sAB4EUdfujFmL/CIVyNS6uZR1RizCkdhPEct9JTsN1GeZLWEXsYYszvDOh02pVThsHq99yLPaqNczonInfz5C9UHOOXdkJS6aVi93nuRZ6mboiJSD5gPtMReZP+/wN+NMfHejEupm4VjntT62J+P+NEYcz2HTZQHWSqhpxKRv2AvYqXFgZQqJCJSBnsrvbYxZoiI3A3UN8Zs8HJoNw1LdLmIyLNZrAesVT5XqSJsMRANtHAsnwBWA5rQC4klEjp/Vncz2C/10rLeJYhSRdOdxph+ItIfwBhzWdLOEq0KnCUSujHmFQARWQqMNcZcdCxXAt7yZmxK3USuiUhp/hyUcCdpJppRBc8SCT0NW2oyBzDGXBCRJt4MSKmbyMvAf4DbRWQF9hLPg7wa0U3GagndR0QqGWMugHNKLKudo1JFkjHmKxHZAzTH3vU51hhzzsth3VSsluzeAnaKyGrHcl/gX16MRynLE5GQDKtSn/24Q0Tu0LK5hcdywxYdBYFSy3RuMsYc8GY8SlmdiGx2sdqZWKw2Y1hRZrmErpTyDhF5GPiPMeZ3EfknEAJM1RZ64bFaLRellPe85EjmrbFfJf8v8J6XY7qpaEJXSnlKamXF+4EFxpiNQEkvxnPT0YSulPKUEyIyD/tcop+JSCk0xxQq7UNXSnmEo5ZLd+AHY8xhEakJBBpjvvRyaDcNTehKKWURejmklFIWoQldKaUsQhO6UkpZhCZ0pZSyCE3oSillEf8PPZivkA4Z09YAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "scores.plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Comparing scores with TripAdvisor\n",
    "\n",
    "Obtained scores can be compared with the feature ratings which were computed by TripAdvisor up to some time ago\n",
    "\n",
    "![hotel ratings](https://www.dropbox.com/s/pq6q9ugsaessow6/hotel-ratings.png?dl=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Activity 3: Classification of Reviews via Supervised Training\n",
    "\n",
    "**Goal:** classify user reviews of movies extracted from IMDB as positive or negative\n",
    "\n",
    "Contrarily to previous activities, this time we will train a classificaton model on existing reviews instead of using manually set keywords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Loading reviews\n",
    "\n",
    "We load reviews from a GZIP-compressed CSV file of 10,000 movie reviews, alternated between positive and negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "download(\"acl-10k.csv.gz\", \"https://www.dropbox.com/s/ug8pr2v53wxntxb/acl-10k.csv.gz?dl=1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reviews = pd.read_csv(\"acl-10k.csv.gz\", sep=\"\\t\", header=None, names=[\"label\", \"text\"], compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pos</td>\n",
       "      <td>Bromwell High is a cartoon comedy. It ran at the same time as some other programs about school l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neg</td>\n",
       "      <td>Story of a man who has unnatural feelings for a pig. Starts out with a opening scene that is a t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pos</td>\n",
       "      <td>If you like adult comedy cartoons, like South Park, then this is nearly a similar format about t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>neg</td>\n",
       "      <td>Robert DeNiro plays the most unbelievably intelligent illiterate of all time. This movie is so w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pos</td>\n",
       "      <td>Bromwell High is nothing short of brilliant. Expertly scripted and perfectly delivered, this sea...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label  \\\n",
       "0   pos   \n",
       "1   neg   \n",
       "2   pos   \n",
       "3   neg   \n",
       "4   pos   \n",
       "\n",
       "                                                                                                  text  \n",
       "0  Bromwell High is a cartoon comedy. It ran at the same time as some other programs about school l...  \n",
       "1  Story of a man who has unnatural feelings for a pig. Starts out with a opening scene that is a t...  \n",
       "2  If you like adult comedy cartoons, like South Park, then this is nearly a similar format about t...  \n",
       "3  Robert DeNiro plays the most unbelievably intelligent illiterate of all time. This movie is so w...  \n",
       "4  Bromwell High is nothing short of brilliant. Expertly scripted and perfectly delivered, this sea...  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In order to validate the goodness of automated classification, we use the _hold-out_ approach: a part of the reviews is used to train a classifier, while the remaining ones are used to assess its accuracy\n",
    "\n",
    "Let's select the first half of the reviews as the _training set_ and the second half as the _test set_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_train = reviews[:5000]\n",
    "reviews_test = reviews[5000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Bag of Words and Vector Space Model\n",
    "\n",
    "In order to train and use a classifier on reviews, we have to define the _features_ which represent them\n",
    "\n",
    "With the _Bag of Words_ model we represent each review as the set of words contained in it, regardless of their order\n",
    "\n",
    "Once defined a set of known words, we can represent each review with a vector indicating for each word the number of occurrencies in the text; a set of reviews can be be consequently represented as a _document-term matrix_ with a row vector for each review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's define a list of example text documents..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [\n",
    "    \"the sky is blue\",\n",
    "    \"sky is blue and sky is beautiful\",\n",
    "    \"the beautiful sky is so blue\",\n",
    "    \"i love blue cheese\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `CountVectorizer` extracts a vector for each document with counts of distinct words in it: we start from creating an \"empty\" vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vect = CountVectorizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We use the `fit_transform` method passing the list of documents to\n",
    "\n",
    "- \"build\" the vector space with dimensions corresponding to words within them (_fit_)\n",
    "- return the document-term matrix representing them (_transform_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm = vect.fit_transform(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The obtained `dtm` matrix contains a row for each document and a column for each distinct word found within documents: we can obtain a list of the words \"learned\" by the vectorizer..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['and', 'beautiful', 'blue', 'cheese', 'is', 'love', 'sky', 'so', 'the']"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's view the matrix as a DataFrame, labeling rows and columns with corresponding documents and features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>and</th>\n",
       "      <th>beautiful</th>\n",
       "      <th>blue</th>\n",
       "      <th>cheese</th>\n",
       "      <th>is</th>\n",
       "      <th>love</th>\n",
       "      <th>sky</th>\n",
       "      <th>so</th>\n",
       "      <th>the</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>the sky is blue</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sky is blue and sky is beautiful</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the beautiful sky is so blue</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i love blue cheese</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  and  beautiful  blue  cheese  is  love  sky  \\\n",
       "the sky is blue                     0          0     1       0   1     0    1   \n",
       "sky is blue and sky is beautiful    1          1     1       0   2     0    2   \n",
       "the beautiful sky is so blue        0          1     1       0   1     0    1   \n",
       "i love blue cheese                  0          0     1       1   0     1    0   \n",
       "\n",
       "                                  so  the  \n",
       "the sky is blue                    0    1  \n",
       "sky is blue and sky is beautiful   0    0  \n",
       "the beautiful sky is so blue       1    1  \n",
       "i love blue cheese                 0    0  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(dtm.toarray(), index=docs, columns=vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the matrix indicates for each document the number of occurrencies of each word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Using the `transform` method, we can represent further documents in the same vector space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_docs = [\"loving this blue sky today\"]\n",
    "new_dtm = vect.transform(new_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>and</th>\n",
       "      <th>beautiful</th>\n",
       "      <th>blue</th>\n",
       "      <th>cheese</th>\n",
       "      <th>is</th>\n",
       "      <th>love</th>\n",
       "      <th>sky</th>\n",
       "      <th>so</th>\n",
       "      <th>the</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>loving this blue sky today</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            and  beautiful  blue  cheese  is  love  sky  so  \\\n",
       "loving this blue sky today    0          0     1       0   0     0    1   0   \n",
       "\n",
       "                            the  \n",
       "loving this blue sky today    0  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(new_dtm.toarray(), index=new_docs, columns=vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that some words of the new document (e.g. \"loving\") are lost in the representation, because they are not known in the vector space, but this is generally a minor problem if the vector space is built on many documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Training a classifier\n",
    "\n",
    "We use the vector space model to represent reviews passed to a classifier: let's create a new vector space..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...and fit it to reviews of the training set only (as we assume to _not_ know in advance documents of the test set), obtaining the document-term matrix representing them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm_train = vect.fit_transform(reviews_train.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We can get the total count of extracted feature words..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36272"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...and see some of them (they are in alphabetical order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['affections', 'affects', 'afficinados', 'affiliated', 'affiliation']"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect.get_feature_names()[1000:1005]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The document-term matrix is _sparse_, meaning that most of its elements are zero. We can verify the ratio of non-zero elements by converting them to booleans and computing the mean value (all non-zero values become 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0037657973092192322"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtm_train.astype(bool).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Such matrix is represented in memory with a space-efficient data structure which explicitly stores non-zero values only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Now we can train any classification model on the generated vectors: let's use for example a logistic regression model\n",
    "\n",
    "As for the vectorizer, we first create the \"empty\" model..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression(solver=\"liblinear\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...then we fit it to the training set, passing the vector representation of the reviews along with their actual labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='liblinear',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(dtm_train, reviews_train.label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Using the classifier\n",
    "\n",
    "Once the classifier is trained, we can use it to estimate labels for further reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_reviews = [\"What an awesome movie!\", \"It was really boring\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first have to use the vectorizer to extract their representation in the vector space..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm_new = vect.transform(new_reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...then we use the `predict` method of the model to get corresponding predicted labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['pos', 'neg'], dtype=object)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(dtm_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Evaluating the classifier\n",
    "\n",
    "We can evaluate the goodness of the classifier by getting predicted labels for reviews in the test set and comparing them with known actual labels\n",
    "\n",
    "Given data and actual labels of the test set, the `score` method of the model computes the _accuracy_ as the ratio of test reviews for which classification is correct\n",
    "\n",
    "We first obtain the document-term matrix for the test set..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm_test = vect.transform(reviews_test.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...then we call the `score` method on it and on the known labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.819"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(dtm_test, reviews_test.label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Creating a pipeline\n",
    "\n",
    "In all the operations above (training, predicting, evaluating) we had to manually convert text reviews into their vector representations before passing them to the model\n",
    "\n",
    "scikit-learn allows to create _pipelines_, which combine a prediction model with a sequence of one or more pre-processing steps into a single object\n",
    "\n",
    "We first create the pipeline by specifying its components, in this case the vectorizer and the actual classifier; each component has a name, allowing it to be referenced after creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "model = Pipeline([\n",
    "    (\"vectorizer\", CountVectorizer()),\n",
    "    (\"classifier\", LogisticRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Now, we can use the pipeline as we used the model above, but passing directly the text of reviews, as the vectorizer is automatically fit to reviews used to fit the model and used to transform all reviews passed to the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rrobby/bbs-lab/.venv/lib/python3.5/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "model.fit(reviews_train.text, reviews_train.label);\n",
    "# \";\" is used to suppress output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['pos', 'neg'], dtype=object)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(new_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.819"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(reviews_test.text, reviews_test.label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We obtain the same result as above, but with cleaner code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Applying tf.idf term weighting\n",
    "\n",
    "The `CountVectorizer` generates vectors with simple counts of occurrencies of terms within a document, without considering the relative importance of such terms with respect to each other\n",
    "\n",
    "The _tf.idf_ term weighting scheme uses a formula with two factors to better evaluate the weight of each term in each document\n",
    "\n",
    "- The _tf_ factor evaluates the _local_ importance of a term in a document: it is usually the usual count of occurrencies of the term (or its logarithm)\n",
    "- The _idf_ factor evaluates the _global_ importance of a term in the set of documents: it is higher for terms appearing in fewer documents, as they are supposed to be more specific\n",
    "\n",
    "In order to use tf.idf in place of raw counts of occurrencies, we simply use `TfidfVectorizer` in place of `CountVectorizer`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's see for example the tf.idf applied to example documents used above..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>and</th>\n",
       "      <th>beautiful</th>\n",
       "      <th>blue</th>\n",
       "      <th>cheese</th>\n",
       "      <th>is</th>\n",
       "      <th>love</th>\n",
       "      <th>sky</th>\n",
       "      <th>so</th>\n",
       "      <th>the</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>the sky is blue</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.399</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.488</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.488</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sky is blue and sky is beautiful</th>\n",
       "      <td>0.441</td>\n",
       "      <td>0.347</td>\n",
       "      <td>0.230</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.562</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.562</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the beautiful sky is so blue</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.432</td>\n",
       "      <td>0.286</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.548</td>\n",
       "      <td>0.432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i love blue cheese</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.346</td>\n",
       "      <td>0.663</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.663</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    and  beautiful   blue  cheese     is  \\\n",
       "the sky is blue                   0.000      0.000  0.399   0.000  0.488   \n",
       "sky is blue and sky is beautiful  0.441      0.347  0.230   0.000  0.562   \n",
       "the beautiful sky is so blue      0.000      0.432  0.286   0.000  0.350   \n",
       "i love blue cheese                0.000      0.000  0.346   0.663  0.000   \n",
       "\n",
       "                                   love    sky     so    the  \n",
       "the sky is blue                   0.000  0.488  0.000  0.603  \n",
       "sky is blue and sky is beautiful  0.000  0.562  0.000  0.000  \n",
       "the beautiful sky is so blue      0.000  0.350  0.548  0.432  \n",
       "i love blue cheese                0.663  0.000  0.000  0.000  "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vect = TfidfVectorizer()\n",
    "dtm = vect.fit_transform(docs)\n",
    "pd.DataFrame(dtm.toarray(), index=docs, columns=vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see e.g. in the last document that \"cheese\" has an higher importance than \"blue\", being a less common and thus more discriminating word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We employ tf.idf in our classification pipeline by replacing `CountVectorizer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Pipeline([\n",
    "    (\"vectorizer\", TfidfVectorizer()),\n",
    "    (\"classifier\", LogisticRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As above, we fit the model on the training set and then evaluate it on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(reviews_train.text, reviews_train.label);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8412"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(reviews_test.text, reviews_test.label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Looking for the most influential words\n",
    "\n",
    "Logistic regression computes the likelihood of a review being positive (or negative) according to the following formula:\n",
    "$$ h_\\theta(\\mathbf{x})=\\frac{1}{1+\\exp\\left(-\\theta_0-\\sum_{i=1}^n{\\theta_i\\cdot x_i}\\right)} $$\n",
    "\n",
    "Every $x_i$ variable indicates the element $i$ of an input vector (i.e. the weight of the $i$-th word in the dictionary), while $\\theta_i$ is the model parameter indicating how much the word contributes to the review being estimated as positive or negative\n",
    "\n",
    "By looking at values of the parameters, we can find out which words contribute the most at the reviews being labeled as positive or negative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The $\\theta_i$ parameters are available as the `coef_` attribute of the `LogisticRegression` model, we get it from the pipeline and print some values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.05091047, -0.01439812, -0.02566154,  0.0457697 ])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_classifier = model.named_steps[\"classifier\"]\n",
    "model_classifier.coef_[0, :4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to make sense of the values, we get from the `TfidfVectorizer` the names of features and match them to values using a series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_vectorizer = model.named_steps[\"vectorizer\"]\n",
    "model_coefs = pd.Series(model_classifier.coef_[0],\n",
    "                        model_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We sort the values in ascending order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_coefs.sort_values(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now at the top of the series we find the terms with the lowest coefficients, which make the model decision most tend to the \"negative\" class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bad      -5.200\n",
       "worst    -4.123\n",
       "awful    -2.801\n",
       "waste    -2.771\n",
       "boring   -2.760\n",
       "dtype: float64"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_coefs.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "...while at the bottom of the series we find terms with the highest coefficients, whose presence makes the review positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "and      2.434\n",
       "well     2.517\n",
       "love     2.688\n",
       "best     3.217\n",
       "great    4.527\n",
       "dtype: float64"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_coefs.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this way, we can generally find out the most important terms in deciding the orientation of a review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Regularization of parameters\n",
    "\n",
    "The logistic regression model uses _regularization_ to prevent parameters from having very high absolute values, which may lead to overfitting\n",
    "\n",
    "The C parameter controls the regularization strength: smaller values lead to stronger regularization, while larger values make the model fit more to training data\n",
    "\n",
    "This parameter can be tuned to improve the model accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's try for example to raise the C parameter from its default value 1 to 10, thus lowering the regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Pipeline([\n",
    "    (\"vectorizer\", TfidfVectorizer()),\n",
    "    (\"classifier\", LogisticRegression(C=10))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(reviews_train.text, reviews_train.label);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8292"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(reviews_test.text, reviews_test.label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case accuracy slightly drops, possibly due to overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "If we check for model parameters, their absolute value are now higher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_classifier = model.named_steps[\"classifier\"]\n",
    "model_vectorizer = model.named_steps[\"vectorizer\"]\n",
    "model_coefs = pd.Series(model_classifier.coef_[0],\n",
    "                        model_vectorizer.get_feature_names())\n",
    "model_coefs.sort_values(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "worst   -9.775\n",
       "bad     -9.499\n",
       "awful   -6.672\n",
       "dtype: float64"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_coefs.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "perfect    6.163\n",
       "best       7.489\n",
       "great      8.935\n",
       "dtype: float64"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_coefs.tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Reducing the dimensionality\n",
    "\n",
    "Considering the number of distinct terms across all training reviews, the dimensionality of the vector space is very high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36272"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Methods exist to reduce the dimensionality in order to lower the time required for training the model with very small repercussion on its accuracy\n",
    "\n",
    "One possibility is to not consider words appearing only in very few reviews, such as very specific terms or misspelled words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We can configure the vectorizer with the `min_df` parameter to exclude terms appearing e.g. in less than 3 training reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Pipeline([\n",
    "    (\"vectorizer\", TfidfVectorizer(min_df=3)),\n",
    "    (\"classifier\", LogisticRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's fit the model as above..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(reviews_train.text, reviews_train.label);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Looking at the fit vectorizer, the number of dimensions is now much lower..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16127"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.named_steps[\"vectorizer\"].get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...but the accuracy is close to the previous value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8424"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(reviews_test.text, reviews_test.label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Stemming\n",
    "\n",
    "Another way to reduce dimensionality is to group similar terms into an unique feature\n",
    "\n",
    "_Stemming_ is the extraction of the morphological root (_stem_) of a word: using stems of words as features in place of words themselves, we obtain a single feature for possibly several single terms with a common stem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We start creating a `PorterStemmer` object, providing a `stem` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = nltk.stem.PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('stem', 'stem')"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps.stem(\"stem\"), ps.stem(\"stemming\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use that to create a function which uses NLTK to tokenize text into words and return a sequence of stems instead of complete words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_with_stemming(text):\n",
    "    return [ps.stem(token) for token\n",
    "        in nltk.tokenize.word_tokenize(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['We', 'have', 'shown', 'mani', 'exampl', '!']"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize_with_stemming(\"We have shown many examples!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In a vectorizer, we can set the `tokenizer` parameter to use our custom tokenization function in place of scikit-learn default one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Pipeline([\n",
    "    (\"vectorizer\", TfidfVectorizer(min_df=3, tokenizer=tokenize_with_stemming)),\n",
    "    (\"classifier\", LogisticRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then fit the model as usual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(reviews_train.text, reviews_train.label);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The number of feature is further reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12534"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.named_steps[\"vectorizer\"].get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computing the accuracy..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8384"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(reviews_test.text, reviews_test.label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...we see in this case a minor loss "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### n-grams\n",
    "\n",
    "An _n-gram_ is a sequence of n consecutive words in a text: in the common cases with n equal to 2 and 3, they are called _bigrams_ and _trigrams_\n",
    "\n",
    "n-grams can be used in addition or replacement to single words as features to represent reviews: they can be useful to spot meaningful expressions composed of more than one word, although we will also get many n-grams with no significant meaning\n",
    "\n",
    "For example, in the sentence \"Sentiment analysis is not bad\" we have meaningful bigrams indicating a concept (\"Sentiment analysis\") and an opinion (\"not bad\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Setting the `ngram_range` parameter of a vectorizer to a tuple `(a,b)`, it will use as features all n-grams with n between a and b; the default value is `(1, 1)`, meaning that only single words (\"1-grams\") are considered\n",
    "\n",
    "Let's see what happens by setting `(1, 2)`, i.e. considering both single words and bigrams, still limiting features to those appearing in 3 reviews at least"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Pipeline([\n",
    "    (\"vectorizer\", TfidfVectorizer(min_df=3, ngram_range=(1, 2))),\n",
    "    (\"classifier\", LogisticRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the model as usual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(reviews_train[\"text\"], reviews_train[\"label\"]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Adding bigrams to single words, the dimensionality is sensibly higher..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71800"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.named_steps[\"vectorizer\"].get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...but in this case we successfully increase the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.851"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(reviews_test[\"text\"], reviews_test[\"label\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Sentiment analysis with NLTK\n",
    "\n",
    "NLTK integrates specific functions for sentiment analysis, allowing to evaluate the subjectivity and the sentiment of text\n",
    "\n",
    "Let's see for example how to classify reviews using VADER (_Valence Aware Dictionary for sEntiment Reasoning_), a lexicon and rule-based sentiment estimator specifically oriented to social media, of which NLTK provides an implementation\n",
    "\n",
    "- **Reference:** Hutto, C. J., and Eric Gilbert. \"VADER: A Parsimonious Rule-Based Model for Sentiment Analysis of Social Media Text.\" _Eighth International AAAI Conference on Weblogs and Social Media_. 2014."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Download the necessary data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /home/rrobby/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"vader_lexicon\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the class and create an analyzer object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "vader = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We can see some words in the VADER lexicon along with the positive or negative orientation assigned to them: we can see that typical social media language is recognized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.7"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vader.lexicon[\"excellent\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.5"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vader.lexicon[\"sux\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2.8"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vader.lexicon[\"wtf\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vader.lexicon[\":-)\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Using the `polarity_score` method, given some text, we obtain a dictionary stating the probability of the sentence being either positive, negative or sentiment-neutral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'compound': 0.431, 'neg': 0.0, 'neu': 0.412, 'pos': 0.588}"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vader.polarity_scores(\"Not a bad movie\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'compound': -0.2755, 'neg': 0.413, 'neu': 0.587, 'pos': 0.0}"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vader.polarity_scores(\"I wouldn't recommend this movie\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'compound': 0.4588, 'neg': 0.0, 'neu': 0.667, 'pos': 0.333}"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vader.polarity_scores(\"This movie is candidated to 3 Academy awards\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the model is reasonably good in detecting compound statements such as negations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's create a function that, given a review, returns a \"pos\" or \"neg\" label according to VADER scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vader_classify(text):\n",
    "    scores = vader.polarity_scores(text)\n",
    "    return \"pos\" if scores[\"pos\"] >= scores[\"neg\"] else \"neg\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the `apply` method of series, we apply the function to each review text obtaining a series of pos/neg labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "vader_preds = reviews_test[\"text\"].apply(vader_classify)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We compare this series with actual labels, obtaining a boolean series stating for which reviews the classifier indicated the correct label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "vader_hits = vader_preds == reviews_test[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True, False,  True])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vader_hits.values[:9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computing the mean, we obtain the ratio of `True` values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6936"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vader_hits.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here VADER achieves a lower accuracy than our supervised model, which however required a large set of pre-labeled reviews to be trained"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exercise 2: test new methods on tweets\n",
    "\n",
    "In this activity we seen two sentiment classification methods\n",
    "- using a classifier trained on the labeled reviews used here\n",
    "- using the pretrained VADER model\n",
    "\n",
    "Test both these new methods on airline tweets from the first activity, giving each tweet a score of -5 or 5 according to the negative or positive response of the classifier, then compare as above summary scores obtained by both methods with ACSI scores\n",
    "\n",
    "Which of the two methods do you expect to be more accurate?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
